{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import BatchNormalization, Concatenate\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy as nps\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import skimage.io as sio\n",
    "import skimage.color as scolor\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#import pickle\n",
    "#import os\n",
    "#import json\n",
    "#import glob\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "#import keras_data_reader as dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_filename = \"datasets/processed/aug_structured_data-liver_only.hdf5\"\n",
    "hdf_file = h5py.File(hdf_filename, 'r')\n",
    "train_data = hdf_file['train_data']\n",
    "train_labels = hdf_file[\"train_labels\"]\n",
    "val_data = hdf_file['val_data']\n",
    "val_labels = hdf_file[\"val_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(240, 232, 1))\n",
    "\n",
    "# downsampling\n",
    "xc1 = Conv2D(32, (3, 3), padding='same', activation='relu', strides=(1, 1))(inputs)\n",
    "xc1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(xc1)\n",
    "xc2 = Conv2D(64, (3, 3), padding='same', activation='relu', strides=(1, 1))(xc1)\n",
    "xc2 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(xc2)\n",
    "xmp3 = MaxPooling2D(pool_size=(2, 2))(xc2)\n",
    "\n",
    "xc1b = Conv2D(128, (3, 3), padding='same', activation='relu', strides=(1, 1))(xmp3)\n",
    "xc1b = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(xc1b)\n",
    "xc2b = Conv2D(256, (3, 3), padding='same', activation='relu', strides=(1, 1))(xc1b)\n",
    "xc2b = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(xc2b)\n",
    "xmp3b = MaxPooling2D(pool_size=(2, 2))(xc2b)\n",
    "\n",
    "# upsampling\n",
    "xup4 = UpSampling2D(size=(2, 2), data_format=None)(xmp3b)\n",
    "\n",
    "concat1 = Concatenate(axis=-1)([xup4, xc2b])\n",
    "\n",
    "xct5 = Conv2DTranspose(256, (3, 3), strides=(1, 1), padding='same', data_format=None, activation='relu')(xup4)\n",
    "xct5 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(concat1)\n",
    "xct6 = Conv2DTranspose(128, (3, 3), strides=(1, 1), padding='same', data_format=None, activation='relu')(xct5)\n",
    "xct6 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(xct6)\n",
    "\n",
    "# upsampling\n",
    "xup4b = UpSampling2D(size=(2, 2), data_format=None)(xct6)\n",
    "\n",
    "concat2 = Concatenate(axis=-1)([xup4b, xc2])\n",
    "\n",
    "xct5b = Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same', data_format=None, activation='relu')(concat2)\n",
    "xct5b = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(xct5b)\n",
    "xct6b = Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', data_format=None, activation='relu')(xct5b)\n",
    "xct6b = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(xct6b)\n",
    "\n",
    "predictions = Conv2D(3, (1, 1), padding='same', activation='softmax')(xct6b)\n",
    "#predictions = BatchNormalization()(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "sgd = SGD(lr=0.01)#, clipvalue=0.5)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sys.exit(0)\n",
    "epochs = 5\n",
    "#labels = np.array([1,1,1])\n",
    "model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=epochs, batch_size=8, shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = \"models/segnet-20epoch_aug_structured_data-liver_only.hdf5\"\n",
    "model.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ulozeni vysledku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = hdf_file['test_data']\n",
    "test_labels = hdf_file[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted_labels = model.predict(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_path = \"test_results-20epoch_aug_structured_data-liver_only.hdf5\"\n",
    "hdf5_file = h5py.File(test_results_path , mode='w')\n",
    "hdf5_file.create_dataset(\"test_data\", test_data.shape, np.int8)\n",
    "hdf5_file[\"test_data\"][...] = test_data\n",
    "hdf5_file.create_dataset(\"test_labels\", test_labels.shape, np.int8)\n",
    "hdf5_file[\"test_labels\"][...] = test_labels\n",
    "hdf5_file.create_dataset(\"test_predictions\", test_predicted_labels.shape, np.float)\n",
    "hdf5_file[\"test_predictions\"][...] = test_predicted_labels\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_predicted_labels[39]\n",
    "plt.imshow(res)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_predicted_labels[39]\n",
    "print(res.shape)\n",
    "plt.imshow(res[:,:,1], cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_predicted_labels[39]\n",
    "print(res.shape)\n",
    "plt.imshow(res[:,:,1]>0.33, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = test_labels[39].astype(float)\n",
    "plt.imshow(lab)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_data[39]\n",
    "print(res.shape)\n",
    "plt.imshow(res[:,:,0], cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
