{
 "metadata": {
  "name": "",
  "signature": "sha256:dbc6a850f72c3c867fbd50bdb54ff3ac01a03e58004d458691a861c5d5a569d1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifier as clas\n",
      "import copy\n",
      "import numpy as np\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm = clas.Classifier()\n",
      "svm.create_training_data()\n",
      "#svm.train()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scorings = ['accuracy', \n",
      "            'average_precision',\n",
      "            'f1', 'f1_macro', 'f1_micro', 'f1_weighted',\n",
      "            'neg_log_loss',          \n",
      "            'precision', \n",
      "            'precision_macro',\n",
      "            'precision_micro',\n",
      "            'precision_weighted', \n",
      "            'recall', 'recall_macro', 'recall_micro', 'recall_weighted',\n",
      "            'roc_auc'\n",
      "            ]\n",
      "\n",
      "clustering = ['adjusted_mutual_info_score',\n",
      "              'adjusted_rand_score',\n",
      "              'completeness_score',\n",
      "              'fowlkes_mallows_score',\n",
      "              'homogeneity_score',\n",
      "              'mutual_info_score',\n",
      "              'normalized_mutual_info_score',\n",
      "              'neg_log_loss',\n",
      "              'v_measure_score']\n",
      "\n",
      "regression = ['explained_variance',\n",
      "              'neg_mean_absolute_error',\n",
      "              'neg_mean_squared_error',\n",
      "              'neg_mean_squared_log_error',\n",
      "              'neg_median_absolute_error',\n",
      "              'r2']\n",
      "\n",
      "multilabel_only = ['f1_samples', 'precision_samples', 'recall_samples']\n",
      "#scorings=['accuracy', 'average_precision']\n",
      "scorings = [\"accuracy\", \"precision\", \"recall\", \"f1\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#svm.evaluate(mode=\"train\", cv_scorings=scorings)\n",
      "#svm.extractor.n_negative_patches *= 3\n",
      "#svm.cross_validation(cv_scorings=scorings, extract_new_features=bool(0))\n",
      "svm.evaluate_test(to_train=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print svm.test_classifier.predict(svm.data)\n",
      "print svm.labels\n",
      "\n",
      "TP = 7.0\n",
      "FP = 5.0\n",
      "FN = 2.0\n",
      "print TP / (TP+FP) \n",
      "print TP / (TP+FN) \n",
      "\n",
      "print 1 - float( np.sum(svm.test_classifier.predict(svm.data) != svm.labels)) / len(svm.data)\n",
      "#print cross_val_score(svm.test_classifier, svm.data, svm.labels)\n",
      "\n",
      "print svm.test_classifier.score(svm.data, svm.labels)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.zeros(9)\n",
      "print a\n",
      "print a.reshape(1,-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.dataset.create_dataset_CT()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.extractor.extract_feature_vects(multiple_rois=False, \n",
      "                                     save_features=False,\n",
      "                                     mode=\"transform\")\n",
      "svm.create_training_data()\n",
      "print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.create_training_data(features=svm.extractor.features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.store_results()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(svm.dataset.orig_images)\n",
      "print svm.extractor.n_negatives\n",
      "print svm.extractor.n_negative_patches\n",
      "print len(svm.extractor.features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.extractor.features = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "clf = SVC(kernel=\"linear\", C = 0.1, probability=True, random_state=42)\n",
      "#clas.cross_val_score(clf, svm.data, svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cross_validate(clf, svm.data, svm.labels, scoring=scorings)#, return_train_score=False)\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"accuracy\")\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"precision\")\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"recall\")\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"f1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(svm.data, svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = clf.predict(svm.data), svm.labels\n",
      "print confusion_matrix(yref, ypred)\n",
      "print classification_report(ypred, yref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = svm.test_classifier.predict(svm.data), svm.labels\n",
      "print confusion_matrix(yref, ypred)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = svm.test_classifier.predict(svm.data), svm.labels\n",
      "print accuracy_score(svm.test_classifier.predict(svm.data), svm.labels)\n",
      "a = classification_report(svm.test_classifier.predict(svm.data), svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(a)\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = clf.predict(svm.data), svm.labels\n",
      "print accuracy_score(clf.predict(svm.data), svm.labels)\n",
      "a = classification_report(clf.predict(svm.data), svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.test_classifier = copy.copy(clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import fbeta_score, make_scorer, precision_recall_fscore_support\n",
      "scorer = make_scorer(\"accuracy\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print precision_recall_fscore_support(ypred, yref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import recall_score\n",
      "print recall_score(ypred, yref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print recall_score.__name__+\"__pll\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print svm.data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = clf.predict(svm.data), svm.labels\n",
      "print accuracy_score(clf.predict(svm.data), svm.labels)\n",
      "print classification_report(clf.predict(svm.data), svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Prohlizeni evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import data_reader as dr\n",
      "import file_manager as fm\n",
      "import copy\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "\n",
      "eval_path = \"extractor_test_results/HoG/evaluation/\"\n",
      "eval_path = \"extractor_test_results/2017-10-09__13-31-19-696000-classic/evaluation/\"\n",
      "eval_path = \"extractor_test_results/2017-10-09__20-47-04-898000-jako_vyse_ale_cv=5/evaluation/\"\n",
      "#eval_path = \"extractor_test_results/2017-10-23__17-54-09-392000-B-affine+flip_median9_Coloring27_win48/evaluation/\"\n",
      "evals = [eval_path + imgname for imgname in os.listdir(eval_path) if imgname.endswith('.json')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = list()\n",
      "\n",
      "for eval_file in evals:\n",
      "    scores.append(dr.load_json(eval_file))\n",
      "    scores[-1][\"name\"] = fm.get_imagename(eval_file)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = dict()\n",
      "test_keys = [key for key in scores[0].keys() if \"test\" in key]\n",
      "#test_keys = [key for key in scores[0].keys()]\n",
      "\n",
      "for key in test_keys:\n",
      "    best[key] = list()\n",
      "    sorted_scores = sorted(scores, key=lambda k: np.mean(k[key]))[::-1]\n",
      "    for score in sorted_scores:\n",
      "        best[key].append((score[\"name\"], np.mean(score[key])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_best(mode=\"best\", n_best=5):\n",
      "    scorings = test_keys\n",
      "    if n_best == -1:\n",
      "        n_best = len(best[scorings[0]])+1\n",
      "        \n",
      "    for scoring in scorings:\n",
      "        if mode == \"worst\":\n",
      "            print \"Nejhorsi podle \"+scoring+\": \"\n",
      "            for each in best[scoring][::-1][:n_best]:\n",
      "                print each\n",
      "        else:\n",
      "            print \"Nejlepsi podle \"+scoring+\": \"\n",
      "            for each in best[scoring][:n_best]:\n",
      "                print each"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_best(mode=\"wors\", n_best=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name = 'extracted_features_CV_ori=8_ppc=8_cpb=4_colored'\n",
      "ppc = re.findall(r'ppc\\=\\d+', name)[0]\n",
      "ppc = int(re.findall(r'\\d+', ppc)[0])\n",
      "\n",
      "ppcs = dict()\n",
      "cpbs = dict()\n",
      "oris = dict()\n",
      "\n",
      "keys = [\"test_accuracy\"]\n",
      "keys = [\"test_recall\"]\n",
      "#keys = [\"test_precision\"]\n",
      "#keys = best.keys()\n",
      "\n",
      "for scoring in keys:\n",
      "    for i, (name, value) in enumerate(best[scoring]):\n",
      "        \n",
      "        ppc = re.findall(r'ppc\\=\\d+', name)[0]\n",
      "        ppc = int(re.findall(r'\\d+', ppc)[0])\n",
      "        cpb = re.findall(r'cpb\\=\\d+', name)[0]\n",
      "        cpb = int(re.findall(r'\\d+', cpb)[0])\n",
      "        ori = re.findall(r'ori\\=\\d+', name)[0]\n",
      "        ori = int(re.findall(r'\\d+', ori)[0])\n",
      "        \n",
      "        #if not ori = 16:\n",
      "         #   continue\n",
      "        \n",
      "        if not ppcs.has_key(ppc):\n",
      "            ppcs[ppc] = 0\n",
      "        else:\n",
      "            ppcs[ppc] += i\n",
      "\n",
      "        if not cpbs.has_key(cpb):\n",
      "            cpbs[cpb] = 0\n",
      "        else:\n",
      "            cpbs[cpb] += i  \n",
      "\n",
      "        if not oris.has_key(ori):\n",
      "            oris[ori] = 0\n",
      "        else:\n",
      "            oris[ori] += i\n",
      "            \n",
      "print len(best[best.keys()[0]])        \n",
      "print oris\n",
      "print ppcs\n",
      "print cpbs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import OrderedDict\n",
      "\n",
      "oris_sorted_by_value = OrderedDict(sorted(oris.items(), key=lambda x: x[1]))\n",
      "ppcs_sorted_by_value = OrderedDict(sorted(ppcs.items(), key=lambda x: x[1]))\n",
      "cpbs_sorted_by_value = OrderedDict(sorted(cpbs.items(), key=lambda x: x[1]))\n",
      "\n",
      "print keys\n",
      "print \"ori: \", oris_sorted_by_value\n",
      "print \"ppc: \", ppcs_sorted_by_value\n",
      "print \"cpb: \", cpbs_sorted_by_value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# u medianu nejlepsi 16, 8, 3\n",
      "# u bilatelar: recall nejhorsi: 1\n",
      "#              precision nejhorsi: 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test vsech konfiguraci"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import data_reader as dr\n",
      "import file_manager as fm\n",
      "import copy\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import os.path as op\n",
      "from collections import OrderedDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "irelevant = [\"Bilateral\", \"Bilatelar\", \"HoG\", \"Median\", \"negatives\", \"Orig\", \"positives\", \"All\"]\n",
      "\n",
      "folders = [each for each in os.listdir(\"extractor_test_results\") if not (op.isfile(each) or each in irelevant)]\n",
      "folders48 = [each for each in os.listdir(\"extractor_test_results\") if \"48\" in each and not (op.isfile(each) or each in irelevant)]\n",
      "folders48col = [each for each in os.listdir(\"extractor_test_results\") if \"48\" in each and \"Coloring2\" in each and not (op.isfile(each) or each in irelevant)]\n",
      "folders54 = [each for each in os.listdir(\"extractor_test_results\") if \"48\" not in each and \"Coloring2\" in each and not (op.isfile(each) or each in irelevant)]\n",
      "\n",
      "#folders = folders54\n",
      "folders = folders48\n",
      "#folders = [\"2017-10-23__17-54-09-392000-B-affine+flip_median9_Coloring27_win48\"]\n",
      "#folders = [\"2017-10-22__15-08-21-752000-affine+flip_median9_Coloring27_win=48\", \"2017-10-23__17-54-09-392000-B-affine+flip_median9_Coloring27_win48\"]\n",
      "evaluations = list()\n",
      "\n",
      "oris, ppcs, cpbs = {}, {}, {}\n",
      "\n",
      "scoring = \"precision\"\n",
      "scoring = \"recall\"\n",
      "\n",
      "for folder in folders:\n",
      "    evalpath = \"extractor_test_results/\" + folder + \"/evaluation/\"\n",
      "    for evalname in os.listdir(evalpath):\n",
      "        evaluation = (evalpath + evalname, dr.load_json(evalpath + evalname))\n",
      "        evaluations.append(evaluation)\n",
      "        name = evalname\n",
      "        ppc = re.findall(r'ppc\\=\\d+', name)[0]\n",
      "        ppc = int(re.findall(r'\\d+', ppc)[0])\n",
      "        cpb = re.findall(r'cpb\\=\\d+', name)[0]\n",
      "        cpb = int(re.findall(r'\\d+', cpb)[0])\n",
      "        ori = re.findall(r'ori\\=\\d+', name)[0]\n",
      "        ori = int(re.findall(r'\\d+', ori)[0])\n",
      "        \n",
      "        if not oris.has_key(ori):\n",
      "            oris[ori] = [np.mean(evaluation[1][scoring])]\n",
      "        else:\n",
      "            oris[ori].append(np.mean(evaluation[1][scoring]))\n",
      "            \n",
      "        if not ppcs.has_key(ppc):\n",
      "            ppcs[ppc] = [np.mean(evaluation[1][scoring])]\n",
      "        else:\n",
      "            ppcs[ppc].append(np.mean(evaluation[1][scoring]))\n",
      "            \n",
      "        if not cpbs.has_key(cpb):\n",
      "            cpbs[cpb] = [np.mean(evaluation[1][scoring])]\n",
      "        else:\n",
      "            cpbs[cpb].append(np.mean(evaluation[1][scoring]))\n",
      "        \n",
      "#print oris\n",
      "#print ppcs\n",
      "#print cpbs\n",
      "print len(evaluations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Serazeni podle prumeru u jednotlivych HoG parametru"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_ppc(name):\n",
      "    ppc = re.findall(r'ppc\\=\\d+', name)[0]\n",
      "    ppc = int(re.findall(r'\\d+', ppc)[0])\n",
      "    return ppc\n",
      "def find_cpb(name):\n",
      "    cpb = re.findall(r'cpb\\=\\d+', name)[0]\n",
      "    cpb = int(re.findall(r'\\d+', cpb)[0])\n",
      "    return cpb\n",
      "def find_ori(name):\n",
      "    ori = re.findall(r'ori\\=\\d+', name)[0]\n",
      "    ori = int(re.findall(r'\\d+', ori)[0])\n",
      "    return ori"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ori_avg_recalls = {}\n",
      "for ori, value in oris.items():\n",
      "    ori_avg_recalls[ori] = np.mean(value)\n",
      "    \n",
      "ppc_avg_recalls = {}\n",
      "for ppc, value in ppcs.items():\n",
      "    ppc_avg_recalls[ppc] = np.mean(value)\n",
      "    \n",
      "cpb_avg_recalls = {}\n",
      "for cpb, value in cpbs.items():\n",
      "    cpb_avg_recalls[cpb] = np.mean(value)\n",
      "\n",
      "print ori_avg_recalls\n",
      "print ppc_avg_recalls\n",
      "print cpb_avg_recalls\n",
      "\n",
      "oris_sorted_by_value = OrderedDict(sorted(ori_avg_recalls.items(), key=lambda x: -x[1]))\n",
      "ppcs_sorted_by_value = OrderedDict(sorted(ppc_avg_recalls.items(), key=lambda x: -x[1]))\n",
      "cpbs_sorted_by_value = OrderedDict(sorted(cpb_avg_recalls.items(), key=lambda x: -x[1]))\n",
      "\n",
      "print \"ori: \", oris_sorted_by_value\n",
      "print \"ppc: \", ppcs_sorted_by_value\n",
      "print \"cpb: \", cpbs_sorted_by_value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Vypis prvnich nekolik serazenych konfiguraci"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recalls = {}\n",
      "\n",
      "for conf, value in evaluations:\n",
      "    recalls[conf] = np.mean(value[scoring])\n",
      "\n",
      "ordered = OrderedDict(sorted(recalls.items(), key=lambda x: -x[1]))\n",
      "\n",
      "noris = {}\n",
      "nppcs = {}\n",
      "ncpbs = {}\n",
      "\n",
      "for key1, value in ordered.items()[:]:\n",
      "    key2 = re.sub(\"extractor\\_test\\_results\\/[\\d\\-\\_]+\", \"\", key1)\n",
      "    key3 = re.sub(\"evaluation\", \"\", key2)\n",
      "    key = re.findall(\"ori\\=\\d+\\_+ppc\\=\\d+\\_+cpb=\\d+\", key3)[0]\n",
      "    #print key ,\"....\", value\n",
      "    #if find_ori(key) < 10:\n",
      "    #    print \"\",\n",
      "    #if not \"0-9\" in key3: continue\n",
      "    #if not \"PCA\" in key3: continue\n",
      "        \n",
      "    #print find_ori(key), find_ppc(key), find_cpb(key), \" ..... \", value\n",
      "    print key3, \" .... \", value\n",
      "    \n",
      "    if noris.has_key(find_ori(key)):\n",
      "        noris[find_ori(key)] += 1\n",
      "    else:\n",
      "        noris[find_ori(key)] = 0\n",
      "    \n",
      "    if nppcs.has_key(find_ppc(key)):\n",
      "        nppcs[find_ppc(key)] += 1\n",
      "    else:\n",
      "        nppcs[find_ppc(key)] = 0\n",
      "\n",
      "    if ncpbs.has_key(find_cpb(key)):\n",
      "        ncpbs[find_cpb(key)] += 1\n",
      "    else:\n",
      "        ncpbs[find_cpb(key)] = 0\n",
      "    \n",
      "\n",
      "print OrderedDict(sorted(noris.items(), key=lambda x: -x[1]))\n",
      "print OrderedDict(sorted(nppcs.items(), key=lambda x: -x[1]))\n",
      "print OrderedDict(sorted(ncpbs.items(), key=lambda x: -x[1]))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Vytvoreni struktury"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ori_keys = noris.keys()\n",
      "ppc_keys = nppcs.keys()\n",
      "cpb_keys = ncpbs.keys()\n",
      "\n",
      "hog_param_struct = dict()\n",
      "\n",
      "for orikey in ori_keys:\n",
      "    hog_param_struct[orikey] = dict()\n",
      "    for ppckey in ppc_keys:\n",
      "        hog_param_struct[orikey][ppckey] = dict()\n",
      "        for cpbkey in cpb_keys:\n",
      "            hog_param_struct[orikey][ppckey][cpbkey] = list()\n",
      "\n",
      "for key, value in ordered.items()[:]:\n",
      "    key = re.sub(\"extractor\\_test\\_results\\/[\\d\\-\\_]+\", \"\", key)\n",
      "    key = re.sub(\"evaluation\", \"\", key)\n",
      "    key = re.findall(\"ori\\=\\d+\\_+ppc\\=\\d+\\_+cpb=\\d+\", key)[0]\n",
      "\n",
      "    ori = find_ori(key)\n",
      "    ppc = find_ppc(key)\n",
      "    cpb = find_cpb(key)\n",
      "    \n",
      "    hog_param_struct[ori][ppc][cpb].append(value)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oris_unwanted = []\n",
      "ppcs_unwanted = [10]\n",
      "cpbs_unwanted = [3]\n",
      "\n",
      "print \"Cpb\"\n",
      "for ori in hog_param_struct.keys():\n",
      "    if ori in oris_unwanted: continue\n",
      "    for ppc in hog_param_struct[ori].keys():\n",
      "        if ppc in ppcs_unwanted: continue\n",
      "        best_cpb = {} \n",
      "        for cpb in hog_param_struct[ori][ppc].keys():\n",
      "            best_cpb[cpb] = np.mean(hog_param_struct[ori][ppc][cpb])\n",
      "        print ori, ppc, OrderedDict(sorted(best_cpb.items(), key=lambda x: -x[1]))\n",
      "# pro vetsinu konfiguraci je nejhorsi cpb=3\n",
      "\n",
      "print \"Ppc\"\n",
      "for ori in ori_keys:\n",
      "    if ori in oris_unwanted: continue\n",
      "    for cpb in cpb_keys:\n",
      "        if cpb in cpbs_unwanted: continue\n",
      "        best_ppc = {} \n",
      "        for ppc in ppc_keys:\n",
      "            best_ppc[ppc] = np.mean(hog_param_struct[ori][ppc][cpb])\n",
      "        print ori, cpb, OrderedDict(sorted(best_ppc.items(), key=lambda x: -x[1]))\n",
      "\n",
      "        #print ori, ppc, OrderedDict(sorted(best_cpb.items(), key=lambda x: -x[1]))\n",
      "# pro vetsinu konfiguraci je nejhorsi ppc=10\n",
      "\n",
      "print \"Ori\"\n",
      "for ppc in ppc_keys:\n",
      "    if ppc in ppcs_unwanted: continue\n",
      "    for cpb in cpb_keys:\n",
      "        if cpb in cpbs_unwanted: continue\n",
      "        best_ori = {} \n",
      "        for ori in ori_keys:\n",
      "            best_ori[ori] = np.mean(hog_param_struct[ori][ppc][cpb])\n",
      "        print ppc, cpb, OrderedDict(sorted(best_ori.items(), key=lambda x: -x[1]))\n",
      "# pro vetsinu konfiguraci je nejhorsi ori="
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Serazeni prumeru pro danou HoG konfiguraci"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg = {}\n",
      "\n",
      "for ori in hog_param_struct.keys():\n",
      "    for ppc in hog_param_struct[ori].keys():\n",
      "        for cpb in hog_param_struct[ori][ppc].keys():\n",
      "            avg[(ori, ppc, cpb)] = np.mean(hog_param_struct[ori][ppc][cpb])\n",
      "            \n",
      "avg = OrderedDict(sorted(avg.items(), key=lambda x: -x[1]))\n",
      "\n",
      "for key, value in avg.items():\n",
      "    print key, \" ..... \", value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Poronavani konfiguraci dat"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hog_param_struct_proc = dict()\n",
      "\n",
      "for orikey in ori_keys:\n",
      "    hog_param_struct_proc[orikey] = dict()\n",
      "    for ppckey in ppc_keys:\n",
      "        hog_param_struct_proc[orikey][ppckey] = dict()\n",
      "        for cpbkey in cpb_keys:\n",
      "            hog_param_struct_proc[orikey][ppckey][cpbkey] = dict()\n",
      "\n",
      "for key1, value in ordered.items()[:]:\n",
      "    \n",
      "    key = re.sub(\"extractor\\_test\\_results\\/[\\d\\-\\_]+\", \"\", key1)\n",
      "    key = re.sub(\"evaluation\", \"\", key)\n",
      "    key = re.findall(\"ori\\=\\d+\\_+ppc\\=\\d+\\_+cpb=\\d+\", key)[0]\n",
      "    \n",
      "    ori = find_ori(key)\n",
      "    ppc = find_ppc(key)\n",
      "    cpb = find_cpb(key)\n",
      "\n",
      "    hog_param_struct_proc[ori][ppc][cpb][key1] = value   \n",
      "    \n",
      "mode = \"win\"\n",
      "mode = \"proc\"\n",
      "mode = \"col\"\n",
      "for orikey in ori_keys:\n",
      "    if orikey in oris_unwanted: continue\n",
      "    for ppckey in ppc_keys:\n",
      "        if ppckey in ppcs_unwanted: continue\n",
      "        for cpbkey in cpb_keys:\n",
      "            if cpbkey in cpbs_unwanted: continue\n",
      "            \n",
      "            medians = list()\n",
      "            bilaterals = list()\n",
      "            \n",
      "            coloring = list()\n",
      "            nocoloring = list()\n",
      "            \n",
      "            win48 = list()\n",
      "            win54 = list()\n",
      "            \n",
      "            for key, value in hog_param_struct_proc[orikey][ppckey][cpbkey].items():\n",
      "                if \"median\" in key:\n",
      "                    medians.append(value)\n",
      "                if \"bilat\" in key:\n",
      "                    bilaterals.append(value)\n",
      "                if \"oloring2\" in key:\n",
      "                    coloring.append(value)\n",
      "                if \"NOcolor\" in key:\n",
      "                    nocoloring.append(value)\n",
      "                if \"48\" in key:\n",
      "                    win48.append(value)\n",
      "                else:\n",
      "                    win54.append(value)\n",
      "                key = re.sub(\"extractor\\_test\\_results\\/[\\d\\-\\_]+\", \"\", key1)\n",
      "                key = re.sub(\"evaluation\", \"\", key)\n",
      "            print orikey, ppckey, cpbkey, \":\",\n",
      "            if mode == \"proc\":\n",
      "                print len(medians), len(bilaterals), \"median\", np.mean(medians), \" x \", np.mean(bilaterals), \"bilateral\",\n",
      "                print \"==>\", \"median\" if np.mean(medians) > np.mean(bilaterals) else \"bilateral\"\n",
      "            if mode == \"win\":\n",
      "                print len(win48), len(win54), \"win48\", np.mean(win48), \" x \", np.mean(win54), \"win54\",\n",
      "                print \"==>\", \"win48\" if np.mean(win48) > np.mean(win54) else \"        54\"   \n",
      "            if mode == \"col\":\n",
      "                print len(coloring), len(nocoloring), \"coloring\", np.mean(coloring), \" x \", np.mean(nocoloring), \"no_coloring\",\n",
      "                print \"==>\", \"coloring\" if np.mean(coloring) > np.mean(nocoloring) else \"         no_coloring\" \n",
      "\n",
      "# lepsi je win 48 v drtive vetsine\n",
      "# lepsi je coloring -> ale ne vzdy uplne -> v tech vyznamnych ale ano\n",
      "# lepsi je median, vzdy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Objektove"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "irelevant = [\"Bilateral\", \"Bilatelar\", \"HoG\", \"Median\", \"negatives\", \"Orig\", \"positives\", \"All\"]\n",
      "folders = [each for each in os.listdir(\"extractor_test_results\") if not (op.isfile(each) or each in irelevant)]\n",
      "\n",
      "def get_processing(fname):\n",
      "    fname = fname.lower()\n",
      "    keywords = [\"bilateral\\d*\", \"bilatelar\\d*\", \"median\\d*\"]\n",
      "    for keyword in keywords:\n",
      "        matches = re.findall(keyword, fname)\n",
      "        if len(matches) >= 1:\n",
      "            return matches[0]\n",
      "    return \"no_processing\"\n",
      "\n",
      "def get_coloring(fname):\n",
      "    fname = fname.lower()\n",
      "    keywords = [\"\\_coloring\\d*\", \"\\_nocoloring\\d*\"]\n",
      "    for keyword in keywords:\n",
      "        matches = re.findall(keyword, fname)\n",
      "        if len(matches) >= 1:\n",
      "            return matches[0][1:]\n",
      "    return \"no_coloring\" \n",
      "\n",
      "def get_winsize(fname):\n",
      "    fname = fname.lower()\n",
      "    keywords = [\"\\_wins?i?z?e?\\=*\\d*\"]\n",
      "    for keyword in keywords:\n",
      "        matches = re.findall(keyword, fname)\n",
      "        if len(matches) >= 1:\n",
      "            number = re.findall(\"\\d+\", matches[0])\n",
      "            if len(number) >= 1:\n",
      "                return int(number[0])  \n",
      "    return 54 \n",
      "\n",
      "def get_decomposition(fname):\n",
      "    fname = fname.lower()\n",
      "    keywords = [\"\\_pca\\_*n\\_components\\=\\d*\\-*\\d*\", \"\\_selectkbest\\_*k\\=\\d*\\-*\\d*\\_*function\\=[a-z]*\\-?[a-z]*\"]\n",
      "    for keyword in keywords:\n",
      "        matches = re.findall(keyword, fname)\n",
      "        if len(matches) >= 1:\n",
      "            return matches[0][1:]\n",
      "    return \"no_decomposition\" \n",
      "\n",
      "\n",
      "fname = \"B-affine+flip_median9_Coloring27_win48//CV_ori=15_ppc=4_cpb=1_PCA__n_components=0-8__random-state=None.json\"\n",
      "fname = \"affine+flip_median9_Coloring27_winsize=48//CV_ori=9_ppc=4_cpb=1_SelectKBest__k=718__function=f-classif.json\"\n",
      "print get_processing(fname)\n",
      "print get_coloring(fname)\n",
      "print get_winsize(fname)\n",
      "print get_decomposition(fname)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Evaluation():\n",
      "    \n",
      "    def __init__(self, fname):\n",
      "        \n",
      "        self.fname = fname\n",
      "        \n",
      "        self.processing = get_processing(fname)\n",
      "        self.coloring = get_coloring(fname)\n",
      "        self.decomposition = get_decomposition(fname)\n",
      "        self.winsize = get_winsize(fname)\n",
      "        self.ori = find_ori(fname)\n",
      "        self.ppc = find_ppc(fname)\n",
      "        self.cpb = find_cpb(fname)\n",
      "        self.hog = [self.ori, self.ppc, self.cpb]\n",
      "        \n",
      "        result = dr.load_json(fname)\n",
      "        \n",
      "        self.recall = np.mean(result[\"recall\"])\n",
      "        self.precision = np.mean(result[\"precision\"])\n",
      "        self.accuracy = np.mean(result[\"accuracy\"])\n",
      "        \n",
      "        self.configlabel = re.sub(\".*affine\\+flip\\_+\", \"\", fname)\n",
      "        self.configlabel = re.sub(\"\\/evaluation\\/\", \"\", self.configlabel)\n",
      "        self.configlabel = re.sub(\"random\\-state\", \"r-s\", self.configlabel)\n",
      "        self.configlabel = re.sub(\"CV\\_\", \"_\", self.configlabel)\n",
      "        self.configlabel = re.sub(\"\\.json\", \"\", self.configlabel)\n",
      "        \n",
      "        self.f1 = np.mean(result[\"f1\"])\n",
      "        self.TN = np.mean(result[\"TN\"])\n",
      "        self.TP = np.mean(result[\"TP\"])\n",
      "        self.FP = np.mean(result[\"FP\"])\n",
      "        self.FN = np.mean(result[\"FN\"])\n",
      "    \n",
      "    def __repr__(self):\n",
      "        return self.configlabel\n",
      "    \n",
      "    def __eq__(self, other):\n",
      "        return self.processing == other.processing\n",
      "    \n",
      "    def __ne__(self, other):\n",
      "        return not self.__eq__(other)\n",
      "    \n",
      "    def difference(self, other):\n",
      "        d = 0\n",
      "        d += int(self.processing != other.processing)\n",
      "        d += int(self.coloring != other.coloring)\n",
      "        d += int(self.winsize != other.winsize)\n",
      "        #d += int(self.decomposition != other.decomposition)\n",
      "        d += int(self.ori != other.ori)\n",
      "        d += int(self.ppc != other.ppc)\n",
      "        d += int(self.cpb != other.cpb)\n",
      "        #d += int(self.hog != other.hog)\n",
      "        return d\n",
      "    \n",
      "    def alternative_representation(self, mode=\"processing\"):\n",
      "        label = \"\"\n",
      "        if not mode in \"processing\":\n",
      "            label = label + str(self.processing)+\"_\"\n",
      "        if not mode in \"coloring\":\n",
      "            label = label + str(self.coloring)[:-2]+\"_\"\n",
      "        if not mode in \"winsize\":\n",
      "            label = label + \"ws=\"+str(self.winsize)+\"_\"\n",
      "        #if not mode in \"decomposition\":\n",
      "        #    label = label + \"decomposition=\"+str(self.decomposition)+\"_\"\n",
      "        if not mode in \"hog\":\n",
      "            label = label + \"hog=\"+str(self.hog)+\"_\"\n",
      "        return label\n",
      "    \n",
      "    def is_alternative_to(self, other, mode=\"processing\"):\n",
      "        \n",
      "        if self.processing != other.processing and not mode in \"processing\":\n",
      "            return False\n",
      "        elif self.coloring != other.coloring and not mode in \"coloring\":\n",
      "            return False\n",
      "        elif self.winsize != other.winsize and not mode in \"winsize\":\n",
      "            return False\n",
      "        #elif self.decomposition != other.decomposition and not mode in \"decomposition\":\n",
      "        #    return False\n",
      "        elif self.ori != other.ori and not mode in \"ori\":\n",
      "            return False\n",
      "        elif self.ppc != other.ppc and not mode in \"ppc\":\n",
      "            return False\n",
      "        elif self.cpb != other.cpb and not mode in \"cpb\":\n",
      "            return False\n",
      "        elif str(self.hog) != str(other.hog) and not mode in \"hog\":\n",
      "            return False\n",
      "        else: return True\n",
      "\n",
      "    \n",
      "eval_struct = list()\n",
      "\n",
      "for folder in folders:\n",
      "    evalpath = \"extractor_test_results/\" + folder + \"/evaluation/\"\n",
      "    for evalname in os.listdir(evalpath):\n",
      "        eval_struct.append(Evaluation(evalpath + evalname))\n",
      "        #print folder, eval_struct[-1].winsize\n",
      "\n",
      "\n",
      "win48 = [e for e in eval_struct if 48 == e.winsize]\n",
      "win54 = [e for e in eval_struct if 54 == e.winsize]\n",
      "\n",
      "median9 = [e for e in eval_struct if \"median9\" in e.processing]\n",
      "bilateral = [e for e in eval_struct if \"bilat\" in e.processing]\n",
      "\n",
      "pcas = [e for e in eval_struct if \"pca\" in e.decomposition]\n",
      "kbests = [e for e in eval_struct if \"kbest\" in e.decomposition]\n",
      "\n",
      "colored = [e for e in eval_struct if not \"no\" in e.coloring]\n",
      "nocolored = [e for e in eval_struct if \"no\" in e.coloring]\n",
      "\n",
      "print median9[0].difference(median9[9])\n",
      "print median9[0]\n",
      "print median9[9]\n",
      "\n",
      "print median9[0] == median9[10]\n",
      "print eval_struct[0].is_alternative_to(eval_struct[10], mode=\"processing\")\n",
      "print len(eval_struct), len(bilateral), len(median9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Test processingu \"\"\"\n",
      "interest = pcas\n",
      "    \n",
      "unique_configs = set([e.alternative_representation(mode=\"processing\") for e in interest])\n",
      "results = {key: [] for key in unique_configs}\n",
      "for e in interest:\n",
      "    results[e.alternative_representation(mode=\"processing\")].append(e)\n",
      "\n",
      "for key, result in results.items():\n",
      "    print key, \" -> \", [(e.processing, \"%.4f\" % e.recall) for e in sorted(result, key=lambda x: x.recall, reverse=True)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Test coloringu \"\"\"\n",
      "interest = pcas\n",
      "    \n",
      "unique_configs = set([e.alternative_representation(mode=\"coloring\") for e in interest])\n",
      "results = {key: [] for key in unique_configs}\n",
      "for e in interest:\n",
      "    results[e.alternative_representation(mode=\"coloring\")].append(e)\n",
      "\n",
      "for key, result in results.items():\n",
      "    print key, \"->\", [(e.coloring, \"%.3f\" % e.recall) for e in sorted(result, key=lambda x: x.recall, reverse=True)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Test winsize \"\"\"\n",
      "interest = pcas\n",
      "    \n",
      "unique_configs = set([e.alternative_representation(mode=\"winsize\") for e in interest])\n",
      "results = {key: [] for key in unique_configs}\n",
      "for e in interest:\n",
      "    results[e.alternative_representation(mode=\"winsize\")].append(e)\n",
      "\n",
      "for key, result in results.items():\n",
      "    print key, \"->\", [(e.winsize, \"%.3f\" % e.recall) for e in sorted(result, key=lambda x: x.recall, reverse=True)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Test HOGu \"\"\"\n",
      "interest = pcas\n",
      "    \n",
      "unique_configs = set([e.alternative_representation(mode=\"hog\") for e in interest])\n",
      "results = {key: [] for key in unique_configs}\n",
      "for e in interest:\n",
      "    results[e.alternative_representation(mode=\"hog\")].append(e)\n",
      "\n",
      "for key, result in results.items():\n",
      "    print key, \"->\", [(e.hog, \"%.3f\" % e.recall) for e in sorted(result, key=lambda x: x.recall, reverse=True)]\n",
      "    print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Confussion matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, recall_score, precision_score\n",
      "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict\n",
      "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
      "from sklearn.svm import SVC\n",
      "import data_reader as dr\n",
      "import time\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = dr.load_obj(\"extractor_test_results/All/data.pklz\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, scoring=scorings, n_jobs=-1)\n",
      "# vypsani vysledku\n",
      "print \"[RESULT] Vysledne skore: \"\n",
      "for key, value in scores.items():\n",
      "    if \"test\" in key or \"time\" in key:\n",
      "        print \"    - \", key, \":\", np.mean(value)\n",
      "        \n",
      "# vzdy vyhodi to same \n",
      "# [RESULT] Vysledne skore: \n",
      "#    -  test_f1 : 0.88553008794\n",
      "#    -  test_recall : 0.809521734647\n",
      "#    -  score_time : 8.59933328629\n",
      "#    -  fit_time : 26.6599999269\n",
      "#    -  test_accuracy : 0.894831364062\n",
      "#    -  test_precision : 0.982314078606"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TN, FP, FN, TP = confusion_matrix(y, scores).ravel()\n",
      "print \"TN = \", tn\n",
      "print \"FP = \", fp\n",
      "print \"FN = \", fn\n",
      "print \"TP = \", tp\n",
      "\n",
      "precision = precision_score(y, scores)\n",
      "recall = recall_score(y, scores)\n",
      "f1 = f1_score(y, scores)\n",
      "accuracy = accuracy_score(y, scores)\n",
      "\n",
      "print \"presicion: \", precision\n",
      "print \"   recall: \", recall\n",
      "print \"       f1: \", f1\n",
      "print \" accuracy: \", accuracy\n",
      "\n",
      "scores_to_save = {\"precision\": precision,\n",
      "                  \"recall\": recall,\n",
      "                  \"f1\": f1,\n",
      "                  \"accuracy\": accuracy,\n",
      "                  \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN}\n",
      "\n",
      "print scores_to_save\n",
      "\n",
      "# take vzdy vyhodi to same\n",
      "# TN =  1920\n",
      "# FP =  32\n",
      "# FN =  387\n",
      "# TP =  1645\n",
      "# presicion:  0.9809183065\n",
      "#    recall:  0.809547244094\n",
      "#        f1:  0.887031544891\n",
      "#  accuracy:  0.894829317269"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
      "scores = cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=kf, scoring=scorings, n_jobs=-1)\n",
      "scoresp = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=kf, n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Provnani cross_validate a cross_val_predict \"\"\"\n",
      "\n",
      "indexes = np.arange(0, len(y), len(y)//3)\n",
      "\n",
      "indexes = np.hstack((indexes, len(y)+1))\n",
      "\n",
      "for i in range(3):\n",
      "\n",
      "    print \" ---- Split \", i, \" ------- \"\n",
      "    print indexes[i], \" az \", indexes[i+1]\n",
      "    \n",
      "    tn, fp, fn, tp = confusion_matrix(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]).ravel()\n",
      "    print tn, tp, fn, fp\n",
      "    \n",
      "    print \"presicion: \", precision_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_precision\"][i]\n",
      "    \n",
      "    print \"   recall: \", recall_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_recall\"][i]\n",
      "    \n",
      "    print \"       f1: \", f1_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_f1\"][i]\n",
      "    \n",
      "    print \" accuracy: \", accuracy_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_accuracy\"][i]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test rychlosti"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "#scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=7, n_jobs=-1)\n",
      "print time.time()-t\n",
      "# 104.861999989 s n_jobs=-1 .... cv=7\n",
      "# 224.183000088 bez n_jobs (=1) ... cv=7\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test rychlosti\n",
      "for i in range(2, 7):\n",
      "    \n",
      "    t = time.time()\n",
      "    scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=i)#, n_jobs=-1)\n",
      "    #cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=i)#, n_jobs=-1)\n",
      "    print \"Pro \", i, \" : \", time.time()-t\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cross_validate -> viz papir\n",
      "\n",
      "# cross_val_predict:\n",
      "# --- n_jobs = -1 \n",
      "#   Pro  2  :  16.6150000095\n",
      "#   Pro  3  :  32.2750000954\n",
      "#   Pro  4  :  50.2630000114\n",
      "#   Pro  5  :  72.2149999142\n",
      "#   Pro  6  :  82.4709999561\n",
      "# --- n_jobs nezadano\n",
      "#   Pro  2  :  26.1459999084\n",
      "#   Pro  3  :  58.1630001068\n",
      "#   Pro  4  :  92.4739999771\n",
      "#   Pro  5  :  129.036000013\n",
      "#   Pro  6  :  167.592999935"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=6, n_jobs=-1)\n",
      "#cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=6, n_jobs=-1)\n",
      "print \"Pro 6: \", time.time()-t\n",
      "\n",
      "t = time.time()\n",
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "#cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "#cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "print \"Pro 2x3: \", time.time()-t\n",
      "\n",
      "#     Cross_validate\n",
      "# Pro 6:    95.9859998226\n",
      "# Pro 2x3:  73.6770000458\n",
      "\n",
      "#     Cross_val_predict\n",
      "# Pro 6:    81.0869998932\n",
      "# Pro 2x3:  58.8340001106"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test rozdeleni dat"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "clf = SVC(kernel=\"linear\", C = 0.1, probability=True, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myX = np.array([[6, 1], [1, 9], [8, 1], [1, 5], [6, 2], [6, 1], [3, 1], [2, 9], [2, 6]], dtype=float)\n",
      "myy = np.array([1, -1, 1, -1, 1, 1, 1, -1, -1])\n",
      "\n",
      "indx = np.argsort(myy)[::-1]\n",
      "print indx\n",
      "\n",
      "myX = myX[indx]\n",
      "myy = myy[indx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = train_test_split(myX, myy, shuffle=True, random_state=None, test_size=0.33)\n",
      "print cross_val_predict(clf, myX, myy, cv=3)\n",
      "print myy\n",
      "print cv[2], cv[3]\n",
      "cv = train_test_split(myX, range(myX.shape[0]), shuffle=True, random_state=None, test_size=0.33)\n",
      "print cv[2], cv[3]\n",
      "cv = train_test_split(myX, range(myX.shape[0]), shuffle=True, random_state=None, test_size=0.33)\n",
      "print cv[2], cv[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myX = np.vstack((myX, myX))\n",
      "myy = np.hstack((myy, myy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
      "kf.get_n_splits()\n",
      "\n",
      "\n",
      "print(kf)  \n",
      "for train_index, test_index in kf.split(myX):\n",
      "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "    print(\"TRAIN:\", myy[train_index], \"TEST:\", myy[test_index])\n",
      "    X_train, X_test = myX[train_index], myX[test_index]\n",
      "    y_train, y_test = myy[train_index], myy[test_index]\n",
      "    \n",
      "print cross_val_predict(clf, myX, myy, cv=kf)\n",
      "print myy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skf = StratifiedKFold(n_splits=8)\n",
      "skf.get_n_splits(myX, myy)\n",
      "\n",
      "for train_index, test_index in skf.split(myX, myy):\n",
      "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "    X_train, X_test = myX[train_index], myX[test_index]\n",
      "    y_train, y_test = myy[train_index], myy[test_index]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Rozdeleni dat pro nas dataset \"\"\"\n",
      "\n",
      "print \"Celkem dat: \"\n",
      "print \"   \" + str( len([s for s in y if s > 0]) ) + \" pozitivnich\"\n",
      "print \"   \" + str( len([s for s in y if s < 0]) ) + \" negativnich\"\n",
      "\n",
      "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
      "\n",
      "print(kf)\n",
      "\n",
      "for train_index, test_index in kf.split(X):\n",
      "    print \"  TRAIN:\" + str( len([s for s in y[train_index] if s > 0]) ) + \" P + \" + str( len([s for s in y[train_index] if s < 0]) ) + \" N \",\n",
      "    print \"  TEST:\" + str( len([s for s in y[test_index] if s > 0]) ) + \" P + \" + str( len([s for s in y[test_index] if s < 0]) ) + \" N \"\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list([1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test prekryti bounding boxu a artefaktu"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import data_reader as dr\n",
      "import file_manager as fm\n",
      "from skimage.morphology import label\n",
      "import matplotlib.pyplot as plt\n",
      "import cv2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = dr.DATAset()\n",
      "dataset.create_dataset_CT()\n",
      "config = dataset.config\n",
      "\n",
      "results = dr.load_json(config[\"result_path\"]+\"results_nms.json\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TP, TN, FP, FN = 0, 0, 0, 0\n",
      "\n",
      "for imgname, boxes in results.items():\n",
      "    \n",
      "    img = dr.load_image(imgname)\n",
      "    mask = fm.get_mask(imgname, config)\n",
      "    imlabel = label(mask)\n",
      "    imlabel[mask==0] = 0\n",
      "    imlabel[mask==2] = 0\n",
      "    blank = np.zeros(img.shape)\n",
      "   \n",
      "    for y, h, x, w in boxes:\n",
      "\n",
      "        frame = img[y:h, x:w]\n",
      "        mask_frame = mask[y:h, x:w]\n",
      "        \n",
      "        na = np.sum((mask_frame==1).astype(int))\n",
      "        nb = frame.shape[0] * frame.shape[1]\n",
      "        \n",
      "        bb_artefact_coverage = float(na) / nb\n",
      "        \n",
      "        print bb_artefact_coverage\n",
      "        \n",
      "        if bb_artefact_coverage < 0.5:\n",
      "            FP += 1\n",
      "            print \"false_positive\"\n",
      "        \n",
      "        print \"-------------------------------\"\n",
      "    \n",
      "    print \"_______________________________\"\n",
      "    artefact_ids = np.unique(imlabel)[1:]\n",
      "    \n",
      "    for i in artefact_ids:\n",
      "        \n",
      "        maxbox = [0, 0]\n",
      "        max_cov = 0\n",
      "        max_id = 0\n",
      "        \n",
      "        for j, (y, h, x, w) in enumerate(boxes):\n",
      "            blank[y:h, x:w] = 1\n",
      "            \n",
      "            na = np.sum((imlabel==i).astype(int))\n",
      "            nab = np.sum((imlabel==i) & (blank==1))\n",
      "\n",
      "            artefact_bb_coverage = float(nab)/na\n",
      "            \n",
      "            if artefact_bb_coverage > max_cov:\n",
      "                max_cov = artefact_bb_coverage\n",
      "                max_id = j\n",
      "                \n",
      "            blank[y:h, x:w] = 0\n",
      "            \n",
      "        print max_cov\n",
      "        \n",
      "        y, h, x, w = max_box = boxes[max_id]\n",
      "        mask_frame = mask[y:h, x:w]\n",
      "        na = np.sum((mask_frame==1).astype(int))\n",
      "        nb = mask_frame.shape[0] * mask_frame.shape[1]\n",
      "        bb_artefact_coverage = float(na) / nb\n",
      "        \n",
      "        print na, nb, max_id\n",
      "        print bb_artefact_coverage\n",
      "        \n",
      "        if bb_artefact_coverage < 0.5:\n",
      "            FN += 1\n",
      "            print \"false_positive\"\n",
      "        else:\n",
      "            TP += 1\n",
      "        \n",
      "        print \"-------------------------------\"\n",
      "\n",
      "        \n",
      "    \n",
      "    print artefact_ids\n",
      "    \n",
      "    print \"TP:\", TP\n",
      "    print \"TN:\", TN\n",
      "    print \"FP:\", FP\n",
      "    print \"FN:\", FN\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plt.imshow(mask)\n",
      "#plt.show()\n",
      "\n",
      "imlabel = label(mask)\n",
      "print np.unique(imlabel)\n",
      "plt.imshow(imlabel)\n",
      "plt.show()\n",
      "\n",
      "imlabel[mask==0] = 0\n",
      "imlabel[mask==2] = 0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TP, TN, FP, FN = 0, 0, 0, 0\n",
      "\n",
      "\n",
      "for imgname, boxes in results.items():\n",
      "    print imgname\n",
      "    TP0, TN0, FP0, FN0 = 0, 0, 0, 0\n",
      "    \n",
      "    img = dr.load_image(imgname)\n",
      "    mask = fm.get_mask(imgname, config)\n",
      "    imlabel = label(mask)\n",
      "    imlabel[(mask==0) | (mask==2)] = 0\n",
      "    #imlabel[mask==2] = 0\n",
      "    blank = np.zeros(img.shape)\n",
      "    artefact_ids = np.unique(imlabel)[1:]\n",
      "    covered_box_ids = list()\n",
      "    \n",
      "    for i in artefact_ids:\n",
      "        covered_by_bb = False\n",
      "        \n",
      "        for j, (y, h, x, w) in enumerate(boxes):\n",
      "            blank[y:h, x:w] = 1\n",
      "            \n",
      "            na = np.sum((imlabel==i).astype(int))\n",
      "            nab = np.sum((imlabel==i) & (blank==1))\n",
      "\n",
      "            artefact_bb_coverage = float(nab)/na\n",
      "            \n",
      "            if artefact_bb_coverage >= 0.5:\n",
      "                covered_by_bb=True\n",
      "                covered_box_ids.append(j)\n",
      "                mask_frame = mask[y:h, x:w]\n",
      "                bb_artefact_coverage = clas.fe.artefact_coverage(mask_frame)\n",
      "                bb_artefact_center_coverage, _ = artefact_center_ellipse_coverage(mask_frame)\n",
      "                if bb_artefact_coverage >= 0.3 and bb_artefact_center_coverage > 0.8:\n",
      "                    print bb_artefact_coverage, bb_artefact_center_coverage\n",
      "                    TP += 1\n",
      "                    TP0 += 1\n",
      "                else:\n",
      "                    print bb_artefact_coverage, bb_artefact_center_coverage\n",
      "                    FP += 1\n",
      "                    FP0 += 1\n",
      "            blank[y:h, x:w] = 0\n",
      "            \n",
      "        if not covered_by_bb:\n",
      "            FN += 1\n",
      "            FN0 += 1\n",
      "    \n",
      "    for j in range(len(boxes)):\n",
      "        if not j in covered_box_ids:\n",
      "            y, h, x, w = boxes[j]\n",
      "            mask_frame = mask[y:h, x:w]\n",
      "            na = np.sum((mask_frame==1).astype(int))\n",
      "            nb = mask_frame.shape[0] * mask_frame.shape[1]\n",
      "            bb_artefact_coverage = float(na) / nb\n",
      "            if bb_artefact_coverage >= 0.5:\n",
      "                TP += 1\n",
      "                TP0 += 1\n",
      "            else:\n",
      "                FP += 1\n",
      "                FP0 += 1\n",
      "    print TP0, TN0, FP0, FN0\n",
      "    #break\n",
      "  \n",
      "    #FP += len(boxes) - len(covered_box_ids)\n",
      "\n",
      "print \"TP:\", TP\n",
      "print \"TN:\", TN\n",
      "print \"FP:\", FP\n",
      "print \"FN:\", FN\n",
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def artefact_center_ellipse_coverage(mask_frame, smaller_scale=0.6):\n",
      "    \"\"\" Vytvori presne uprostred framu oblast ve tvaru elipsy,\n",
      "    a vrati zastoupeni jater uvnitr \"\"\"\n",
      "    \n",
      "    # urceni rozmeru masky\n",
      "    c = np.array(mask_frame.shape) // 2\n",
      "    # vytvoremi masky elipsy\n",
      "    ellipse_mask = clas.fe.ellipse(c, smaller_scale=smaller_scale)\n",
      "    # zprava velikosti podle masky frmu\n",
      "    ellipse_mask = cv2.resize(ellipse_mask.astype(\"uint8\"), mask_frame.shape[::-1], interpolation = cv2.INTER_CUBIC)\n",
      "    \n",
      "    # vytazeni pozadovane oblasti z masky framu\n",
      "    mask_ellipse_frame = mask_frame[ellipse_mask==True]\n",
      "    \n",
      "    # vypocet zastoupeni jater v oblasti\n",
      "    total = np.sum(ellipse_mask >= 1).astype(int)\n",
      "    artefact = np.sum(mask_ellipse_frame == 1).astype(int)\n",
      "    coverage = float(artefact) / total\n",
      "    \n",
      "    return coverage, ellipse_mask"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = dict()\n",
      "print len(a.keys())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.evaluate_nms_results_overlap()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}