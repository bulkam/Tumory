{
 "metadata": {
  "name": "",
  "signature": "sha256:abd3077f285d693fad07e48150a091b757d6a184ff76ba9d73e73c21219a4c67"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifier as clas\n",
      "import copy\n",
      "import numpy as np\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm = clas.Classifier()\n",
      "svm.create_training_data()\n",
      "#svm.train()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scorings = ['accuracy', \n",
      "            'average_precision',\n",
      "            'f1', 'f1_macro', 'f1_micro', 'f1_weighted',\n",
      "            'neg_log_loss',          \n",
      "            'precision', \n",
      "            'precision_macro',\n",
      "            'precision_micro',\n",
      "            'precision_weighted', \n",
      "            'recall', 'recall_macro', 'recall_micro', 'recall_weighted',\n",
      "            'roc_auc'\n",
      "            ]\n",
      "\n",
      "clustering = ['adjusted_mutual_info_score',\n",
      "              'adjusted_rand_score',\n",
      "              'completeness_score',\n",
      "              'fowlkes_mallows_score',\n",
      "              'homogeneity_score',\n",
      "              'mutual_info_score',\n",
      "              'normalized_mutual_info_score',\n",
      "              'neg_log_loss',\n",
      "              'v_measure_score']\n",
      "\n",
      "regression = ['explained_variance',\n",
      "              'neg_mean_absolute_error',\n",
      "              'neg_mean_squared_error',\n",
      "              'neg_mean_squared_log_error',\n",
      "              'neg_median_absolute_error',\n",
      "              'r2']\n",
      "\n",
      "multilabel_only = ['f1_samples', 'precision_samples', 'recall_samples']\n",
      "#scorings=['accuracy', 'average_precision']\n",
      "scorings = [\"accuracy\", \"precision\", \"recall\", \"f1\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#svm.evaluate(mode=\"train\", cv_scorings=scorings)\n",
      "#svm.extractor.n_negative_patches *= 3\n",
      "#svm.cross_validation(cv_scorings=scorings, extract_new_features=bool(0))\n",
      "svm.evaluate_test(to_train=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print svm.test_classifier.predict(svm.data)\n",
      "print svm.labels\n",
      "\n",
      "TP = 7.0\n",
      "FP = 5.0\n",
      "FN = 2.0\n",
      "print TP / (TP+FP) \n",
      "print TP / (TP+FN) \n",
      "\n",
      "print 1 - float( np.sum(svm.test_classifier.predict(svm.data) != svm.labels)) / len(svm.data)\n",
      "#print cross_val_score(svm.test_classifier, svm.data, svm.labels)\n",
      "\n",
      "print svm.test_classifier.score(svm.data, svm.labels)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.zeros(9)\n",
      "print a\n",
      "print a.reshape(1,-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.dataset.create_dataset_CT()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.extractor.extract_feature_vects(multiple_rois=False, \n",
      "                                     save_features=False,\n",
      "                                     mode=\"transform\")\n",
      "svm.create_training_data()\n",
      "print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.create_training_data(features=svm.extractor.features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.store_results()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(svm.dataset.orig_images)\n",
      "print svm.extractor.n_negatives\n",
      "print svm.extractor.n_negative_patches\n",
      "print len(svm.extractor.features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.extractor.features = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "clf = SVC(kernel=\"linear\", C = 0.1, probability=True, random_state=42)\n",
      "#clas.cross_val_score(clf, svm.data, svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cross_validate(clf, svm.data, svm.labels, scoring=scorings)#, return_train_score=False)\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"accuracy\")\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"precision\")\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"recall\")\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"f1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(svm.data, svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = clf.predict(svm.data), svm.labels\n",
      "print confusion_matrix(yref, ypred)\n",
      "print classification_report(ypred, yref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = svm.test_classifier.predict(svm.data), svm.labels\n",
      "print confusion_matrix(yref, ypred)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = svm.test_classifier.predict(svm.data), svm.labels\n",
      "print accuracy_score(svm.test_classifier.predict(svm.data), svm.labels)\n",
      "a = classification_report(svm.test_classifier.predict(svm.data), svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(a)\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = clf.predict(svm.data), svm.labels\n",
      "print accuracy_score(clf.predict(svm.data), svm.labels)\n",
      "a = classification_report(clf.predict(svm.data), svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.test_classifier = copy.copy(clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import fbeta_score, make_scorer, precision_recall_fscore_support\n",
      "scorer = make_scorer(\"accuracy\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print precision_recall_fscore_support(ypred, yref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import recall_score\n",
      "print recall_score(ypred, yref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print recall_score.__name__+\"__pll\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print svm.data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = clf.predict(svm.data), svm.labels\n",
      "print accuracy_score(clf.predict(svm.data), svm.labels)\n",
      "print classification_report(clf.predict(svm.data), svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Prohlizeni evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import data_reader as dr\n",
      "import file_manager as fm\n",
      "import copy\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "\n",
      "eval_path = \"extractor_test_results/HoG/evaluation/\"\n",
      "eval_path = \"extractor_test_results/2017-10-09__13-31-19-696000-classic/evaluation/\"\n",
      "eval_path = \"extractor_test_results/2017-10-09__20-47-04-898000-jako_vyse_ale_cv=5/evaluation/\"\n",
      "evals = [eval_path + imgname for imgname in os.listdir(eval_path) if imgname.endswith('.json') and not ('AFFINE' in imgname)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = list()\n",
      "\n",
      "for eval_file in evals:\n",
      "    scores.append(dr.load_json(eval_file))\n",
      "    scores[-1][\"name\"] = fm.get_imagename(eval_file)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = dict()\n",
      "test_keys = [key for key in scores[0].keys() if \"test\" in key]\n",
      "\n",
      "for key in test_keys:\n",
      "    best[key] = list()\n",
      "    sorted_scores = sorted(scores, key=lambda k: np.mean(k[key]))[::-1]\n",
      "    for score in sorted_scores:\n",
      "        best[key].append((score[\"name\"], np.mean(score[key])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_best(mode=\"best\", n_best=5):\n",
      "    scorings = test_keys\n",
      "    if n_best == -1:\n",
      "        n_best = len(best[scorings[0]])+1\n",
      "        \n",
      "    for scoring in scorings:\n",
      "        if mode == \"worst\":\n",
      "            print \"Nejhorsi podle \"+scoring+\": \"\n",
      "            for each in best[scoring][::-1][:n_best]:\n",
      "                print each\n",
      "        else:\n",
      "            print \"Nejlepsi podle \"+scoring+\": \"\n",
      "            for each in best[scoring][:n_best]:\n",
      "                print each"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_best(mode=\"wors\", n_best=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name = 'extracted_features_CV_ori=8_ppc=8_cpb=4_colored'\n",
      "ppc = re.findall(r'ppc\\=\\d+', name)[0]\n",
      "ppc = int(re.findall(r'\\d+', ppc)[0])\n",
      "\n",
      "ppcs = dict()\n",
      "cpbs = dict()\n",
      "oris = dict()\n",
      "\n",
      "keys = [\"test_accuracy\"]\n",
      "keys = [\"test_recall\"]\n",
      "#keys = [\"test_precision\"]\n",
      "#keys = best.keys()\n",
      "\n",
      "for scoring in keys:\n",
      "    for i, (name, value) in enumerate(best[scoring]):\n",
      "        \n",
      "        ppc = re.findall(r'ppc\\=\\d+', name)[0]\n",
      "        ppc = int(re.findall(r'\\d+', ppc)[0])\n",
      "        cpb = re.findall(r'cpb\\=\\d+', name)[0]\n",
      "        cpb = int(re.findall(r'\\d+', cpb)[0])\n",
      "        ori = re.findall(r'ori\\=\\d+', name)[0]\n",
      "        ori = int(re.findall(r'\\d+', ori)[0])\n",
      "        \n",
      "        #if not ori = 16:\n",
      "         #   continue\n",
      "        \n",
      "        if not ppcs.has_key(ppc):\n",
      "            ppcs[ppc] = 0\n",
      "        else:\n",
      "            ppcs[ppc] += i\n",
      "\n",
      "        if not cpbs.has_key(cpb):\n",
      "            cpbs[cpb] = 0\n",
      "        else:\n",
      "            cpbs[cpb] += i  \n",
      "\n",
      "        if not oris.has_key(ori):\n",
      "            oris[ori] = 0\n",
      "        else:\n",
      "            oris[ori] += i\n",
      "            \n",
      "print len(best[best.keys()[0]])        \n",
      "print oris\n",
      "print ppcs\n",
      "print cpbs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import OrderedDict\n",
      "\n",
      "oris_sorted_by_value = OrderedDict(sorted(oris.items(), key=lambda x: x[1]))\n",
      "ppcs_sorted_by_value = OrderedDict(sorted(ppcs.items(), key=lambda x: x[1]))\n",
      "cpbs_sorted_by_value = OrderedDict(sorted(cpbs.items(), key=lambda x: x[1]))\n",
      "\n",
      "print keys\n",
      "print \"ori: \", oris_sorted_by_value\n",
      "print \"ppc: \", ppcs_sorted_by_value\n",
      "print \"cpb: \", cpbs_sorted_by_value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# u medianu nejlepsi 16, 8, 3\n",
      "# u bilatelar: recall nejhorsi: 1\n",
      "#              precision nejhorsi: 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Confussion matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, recall_score, precision_score\n",
      "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict\n",
      "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
      "from sklearn.svm import SVC\n",
      "import data_reader as dr\n",
      "import time\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = dr.load_obj(\"extractor_test_results/All/data.pklz\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, scoring=scorings, n_jobs=-1)\n",
      "# vypsani vysledku\n",
      "print \"[RESULT] Vysledne skore: \"\n",
      "for key, value in scores.items():\n",
      "    if \"test\" in key or \"time\" in key:\n",
      "        print \"    - \", key, \":\", np.mean(value)\n",
      "        \n",
      "# vzdy vyhodi to same \n",
      "# [RESULT] Vysledne skore: \n",
      "#    -  test_f1 : 0.88553008794\n",
      "#    -  test_recall : 0.809521734647\n",
      "#    -  score_time : 8.59933328629\n",
      "#    -  fit_time : 26.6599999269\n",
      "#    -  test_accuracy : 0.894831364062\n",
      "#    -  test_precision : 0.982314078606"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TN, FP, FN, TP = confusion_matrix(y, scores).ravel()\n",
      "print \"TN = \", tn\n",
      "print \"FP = \", fp\n",
      "print \"FN = \", fn\n",
      "print \"TP = \", tp\n",
      "\n",
      "precision = precision_score(y, scores)\n",
      "recall = recall_score(y, scores)\n",
      "f1 = f1_score(y, scores)\n",
      "accuracy = accuracy_score(y, scores)\n",
      "\n",
      "print \"presicion: \", precision\n",
      "print \"   recall: \", recall\n",
      "print \"       f1: \", f1\n",
      "print \" accuracy: \", accuracy\n",
      "\n",
      "scores_to_save = {\"precision\": precision,\n",
      "                  \"recall\": recall,\n",
      "                  \"f1\": f1,\n",
      "                  \"accuracy\": accuracy,\n",
      "                  \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN}\n",
      "\n",
      "print scores_to_save\n",
      "\n",
      "# take vzdy vyhodi to same\n",
      "# TN =  1920\n",
      "# FP =  32\n",
      "# FN =  387\n",
      "# TP =  1645\n",
      "# presicion:  0.9809183065\n",
      "#    recall:  0.809547244094\n",
      "#        f1:  0.887031544891\n",
      "#  accuracy:  0.894829317269"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
      "scores = cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=kf, scoring=scorings, n_jobs=-1)\n",
      "scoresp = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=kf, n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Provnani cross_validate a cross_val_predict \"\"\"\n",
      "\n",
      "indexes = np.arange(0, len(y), len(y)//3)\n",
      "\n",
      "indexes = np.hstack((indexes, len(y)+1))\n",
      "\n",
      "for i in range(3):\n",
      "\n",
      "    print \" ---- Split \", i, \" ------- \"\n",
      "    print indexes[i], \" az \", indexes[i+1]\n",
      "    \n",
      "    tn, fp, fn, tp = confusion_matrix(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]).ravel()\n",
      "    print tn, tp, fn, fp\n",
      "    \n",
      "    print \"presicion: \", precision_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_precision\"][i]\n",
      "    \n",
      "    print \"   recall: \", recall_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_recall\"][i]\n",
      "    \n",
      "    print \"       f1: \", f1_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_f1\"][i]\n",
      "    \n",
      "    print \" accuracy: \", accuracy_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_accuracy\"][i]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test rychlosti"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "#scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=7, n_jobs=-1)\n",
      "print time.time()-t\n",
      "# 104.861999989 s n_jobs=-1 .... cv=7\n",
      "# 224.183000088 bez n_jobs (=1) ... cv=7\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test rychlosti\n",
      "for i in range(2, 7):\n",
      "    \n",
      "    t = time.time()\n",
      "    scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=i)#, n_jobs=-1)\n",
      "    #cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=i)#, n_jobs=-1)\n",
      "    print \"Pro \", i, \" : \", time.time()-t\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cross_validate -> viz papir\n",
      "\n",
      "# cross_val_predict:\n",
      "# --- n_jobs = -1 \n",
      "#   Pro  2  :  16.6150000095\n",
      "#   Pro  3  :  32.2750000954\n",
      "#   Pro  4  :  50.2630000114\n",
      "#   Pro  5  :  72.2149999142\n",
      "#   Pro  6  :  82.4709999561\n",
      "# --- n_jobs nezadano\n",
      "#   Pro  2  :  26.1459999084\n",
      "#   Pro  3  :  58.1630001068\n",
      "#   Pro  4  :  92.4739999771\n",
      "#   Pro  5  :  129.036000013\n",
      "#   Pro  6  :  167.592999935"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=6, n_jobs=-1)\n",
      "#cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=6, n_jobs=-1)\n",
      "print \"Pro 6: \", time.time()-t\n",
      "\n",
      "t = time.time()\n",
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "#cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "#cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "print \"Pro 2x3: \", time.time()-t\n",
      "\n",
      "#     Cross_validate\n",
      "# Pro 6:    95.9859998226\n",
      "# Pro 2x3:  73.6770000458\n",
      "\n",
      "#     Cross_val_predict\n",
      "# Pro 6:    81.0869998932\n",
      "# Pro 2x3:  58.8340001106"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test rozdeleni dat"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "clf = SVC(kernel=\"linear\", C = 0.1, probability=True, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myX = np.array([[6, 1], [1, 9], [8, 1], [1, 5], [6, 2], [6, 1], [3, 1], [2, 9], [2, 6]], dtype=float)\n",
      "myy = np.array([1, -1, 1, -1, 1, 1, 1, -1, -1])\n",
      "\n",
      "indx = np.argsort(myy)[::-1]\n",
      "print indx\n",
      "\n",
      "myX = myX[indx]\n",
      "myy = myy[indx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = train_test_split(myX, myy, shuffle=True, random_state=None, test_size=0.33)\n",
      "print cross_val_predict(clf, myX, myy, cv=3)\n",
      "print myy\n",
      "print cv[2], cv[3]\n",
      "cv = train_test_split(myX, range(myX.shape[0]), shuffle=True, random_state=None, test_size=0.33)\n",
      "print cv[2], cv[3]\n",
      "cv = train_test_split(myX, range(myX.shape[0]), shuffle=True, random_state=None, test_size=0.33)\n",
      "print cv[2], cv[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myX = np.vstack((myX, myX))\n",
      "myy = np.hstack((myy, myy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
      "kf.get_n_splits()\n",
      "\n",
      "\n",
      "print(kf)  \n",
      "for train_index, test_index in kf.split(myX):\n",
      "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "    print(\"TRAIN:\", myy[train_index], \"TEST:\", myy[test_index])\n",
      "    X_train, X_test = myX[train_index], myX[test_index]\n",
      "    y_train, y_test = myy[train_index], myy[test_index]\n",
      "    \n",
      "print cross_val_predict(clf, myX, myy, cv=kf)\n",
      "print myy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skf = StratifiedKFold(n_splits=8)\n",
      "skf.get_n_splits(myX, myy)\n",
      "\n",
      "for train_index, test_index in skf.split(myX, myy):\n",
      "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "    X_train, X_test = myX[train_index], myX[test_index]\n",
      "    y_train, y_test = myy[train_index], myy[test_index]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Rozdeleni dat pro nas dataset \"\"\"\n",
      "\n",
      "print \"Celkem dat: \"\n",
      "print \"   \" + str( len([s for s in y if s > 0]) ) + \" pozitivnich\"\n",
      "print \"   \" + str( len([s for s in y if s < 0]) ) + \" negativnich\"\n",
      "\n",
      "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
      "\n",
      "print(kf)\n",
      "\n",
      "for train_index, test_index in kf.split(X):\n",
      "    print \"  TRAIN:\" + str( len([s for s in y[train_index] if s > 0]) ) + \" P + \" + str( len([s for s in y[train_index] if s < 0]) ) + \" N \",\n",
      "    print \"  TEST:\" + str( len([s for s in y[test_index] if s > 0]) ) + \" P + \" + str( len([s for s in y[test_index] if s < 0]) ) + \" N \"\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list([1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test prekryti bounding boxu a artefaktu"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import data_reader as dr\n",
      "import file_manager as fm\n",
      "from skimage.morphology import label\n",
      "import matplotlib.pyplot as plt\n",
      "import cv2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = dr.DATAset()\n",
      "dataset.create_dataset_CT()\n",
      "config = dataset.config\n",
      "\n",
      "results = dr.load_json(config[\"result_path\"]+\"results_nms.json\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TP, TN, FP, FN = 0, 0, 0, 0\n",
      "\n",
      "for imgname, boxes in results.items():\n",
      "    \n",
      "    img = dr.load_image(imgname)\n",
      "    mask = fm.get_mask(imgname, config)\n",
      "    imlabel = label(mask)\n",
      "    imlabel[mask==0] = 0\n",
      "    imlabel[mask==2] = 0\n",
      "    blank = np.zeros(img.shape)\n",
      "   \n",
      "    for y, h, x, w in boxes:\n",
      "\n",
      "        frame = img[y:h, x:w]\n",
      "        mask_frame = mask[y:h, x:w]\n",
      "        \n",
      "        na = np.sum((mask_frame==1).astype(int))\n",
      "        nb = frame.shape[0] * frame.shape[1]\n",
      "        \n",
      "        bb_artefact_coverage = float(na) / nb\n",
      "        \n",
      "        print bb_artefact_coverage\n",
      "        \n",
      "        if bb_artefact_coverage < 0.5:\n",
      "            FP += 1\n",
      "            print \"false_positive\"\n",
      "        \n",
      "        print \"-------------------------------\"\n",
      "    \n",
      "    print \"_______________________________\"\n",
      "    artefact_ids = np.unique(imlabel)[1:]\n",
      "    \n",
      "    for i in artefact_ids:\n",
      "        \n",
      "        maxbox = [0, 0]\n",
      "        max_cov = 0\n",
      "        max_id = 0\n",
      "        \n",
      "        for j, (y, h, x, w) in enumerate(boxes):\n",
      "            blank[y:h, x:w] = 1\n",
      "            \n",
      "            na = np.sum((imlabel==i).astype(int))\n",
      "            nab = np.sum((imlabel==i) & (blank==1))\n",
      "\n",
      "            artefact_bb_coverage = float(nab)/na\n",
      "            \n",
      "            if artefact_bb_coverage > max_cov:\n",
      "                max_cov = artefact_bb_coverage\n",
      "                max_id = j\n",
      "                \n",
      "            blank[y:h, x:w] = 0\n",
      "            \n",
      "        print max_cov\n",
      "        \n",
      "        y, h, x, w = max_box = boxes[max_id]\n",
      "        mask_frame = mask[y:h, x:w]\n",
      "        na = np.sum((mask_frame==1).astype(int))\n",
      "        nb = mask_frame.shape[0] * mask_frame.shape[1]\n",
      "        bb_artefact_coverage = float(na) / nb\n",
      "        \n",
      "        print na, nb, max_id\n",
      "        print bb_artefact_coverage\n",
      "        \n",
      "        if bb_artefact_coverage < 0.5:\n",
      "            FN += 1\n",
      "            print \"false_positive\"\n",
      "        else:\n",
      "            TP += 1\n",
      "        \n",
      "        print \"-------------------------------\"\n",
      "\n",
      "        \n",
      "    \n",
      "    print artefact_ids\n",
      "    \n",
      "    print \"TP:\", TP\n",
      "    print \"TN:\", TN\n",
      "    print \"FP:\", FP\n",
      "    print \"FN:\", FN\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plt.imshow(mask)\n",
      "#plt.show()\n",
      "\n",
      "imlabel = label(mask)\n",
      "print np.unique(imlabel)\n",
      "plt.imshow(imlabel)\n",
      "plt.show()\n",
      "\n",
      "imlabel[mask==0] = 0\n",
      "imlabel[mask==2] = 0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TP, TN, FP, FN = 0, 0, 0, 0\n",
      "\n",
      "\n",
      "for imgname, boxes in results.items():\n",
      "    print imgname\n",
      "    TP0, TN0, FP0, FN0 = 0, 0, 0, 0\n",
      "    \n",
      "    img = dr.load_image(imgname)\n",
      "    mask = fm.get_mask(imgname, config)\n",
      "    imlabel = label(mask)\n",
      "    imlabel[(mask==0) | (mask==2)] = 0\n",
      "    #imlabel[mask==2] = 0\n",
      "    blank = np.zeros(img.shape)\n",
      "    artefact_ids = np.unique(imlabel)[1:]\n",
      "    covered_box_ids = list()\n",
      "    \n",
      "    for i in artefact_ids:\n",
      "        covered_by_bb = False\n",
      "        \n",
      "        for j, (y, h, x, w) in enumerate(boxes):\n",
      "            blank[y:h, x:w] = 1\n",
      "            \n",
      "            na = np.sum((imlabel==i).astype(int))\n",
      "            nab = np.sum((imlabel==i) & (blank==1))\n",
      "\n",
      "            artefact_bb_coverage = float(nab)/na\n",
      "            \n",
      "            if artefact_bb_coverage >= 0.5:\n",
      "                covered_by_bb=True\n",
      "                covered_box_ids.append(j)\n",
      "                mask_frame = mask[y:h, x:w]\n",
      "                bb_artefact_coverage = clas.fe.artefact_coverage(mask_frame)\n",
      "                bb_artefact_center_coverage, _ = artefact_center_ellipse_coverage(mask_frame)\n",
      "                if bb_artefact_coverage >= 0.3 and bb_artefact_center_coverage > 0.8:\n",
      "                    print bb_artefact_coverage, bb_artefact_center_coverage\n",
      "                    TP += 1\n",
      "                    TP0 += 1\n",
      "                else:\n",
      "                    print bb_artefact_coverage, bb_artefact_center_coverage\n",
      "                    FP += 1\n",
      "                    FP0 += 1\n",
      "            blank[y:h, x:w] = 0\n",
      "            \n",
      "        if not covered_by_bb:\n",
      "            FN += 1\n",
      "            FN0 += 1\n",
      "    \n",
      "    for j in range(len(boxes)):\n",
      "        if not j in covered_box_ids:\n",
      "            y, h, x, w = boxes[j]\n",
      "            mask_frame = mask[y:h, x:w]\n",
      "            na = np.sum((mask_frame==1).astype(int))\n",
      "            nb = mask_frame.shape[0] * mask_frame.shape[1]\n",
      "            bb_artefact_coverage = float(na) / nb\n",
      "            if bb_artefact_coverage >= 0.5:\n",
      "                TP += 1\n",
      "                TP0 += 1\n",
      "            else:\n",
      "                FP += 1\n",
      "                FP0 += 1\n",
      "    print TP0, TN0, FP0, FN0\n",
      "    #break\n",
      "  \n",
      "    #FP += len(boxes) - len(covered_box_ids)\n",
      "\n",
      "print \"TP:\", TP\n",
      "print \"TN:\", TN\n",
      "print \"FP:\", FP\n",
      "print \"FN:\", FN\n",
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def artefact_center_ellipse_coverage(mask_frame, smaller_scale=0.6):\n",
      "    \"\"\" Vytvori presne uprostred framu oblast ve tvaru elipsy,\n",
      "    a vrati zastoupeni jater uvnitr \"\"\"\n",
      "    \n",
      "    # urceni rozmeru masky\n",
      "    c = np.array(mask_frame.shape) // 2\n",
      "    # vytvoremi masky elipsy\n",
      "    ellipse_mask = clas.fe.ellipse(c, smaller_scale=smaller_scale)\n",
      "    # zprava velikosti podle masky frmu\n",
      "    ellipse_mask = cv2.resize(ellipse_mask.astype(\"uint8\"), mask_frame.shape[::-1], interpolation = cv2.INTER_CUBIC)\n",
      "    \n",
      "    # vytazeni pozadovane oblasti z masky framu\n",
      "    mask_ellipse_frame = mask_frame[ellipse_mask==True]\n",
      "    \n",
      "    # vypocet zastoupeni jater v oblasti\n",
      "    total = np.sum(ellipse_mask >= 1).astype(int)\n",
      "    artefact = np.sum(mask_ellipse_frame == 1).astype(int)\n",
      "    coverage = float(artefact) / total\n",
      "    \n",
      "    return coverage, ellipse_mask"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = dict()\n",
      "print len(a.keys())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.evaluate_nms_results_overlap()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}