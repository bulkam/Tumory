{
 "metadata": {
  "name": "",
  "signature": "sha256:003819aace585bc7017262a9130d6abe59864714796693b00b07f79f75aec5b2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import classifier as clas\n",
      "import copy\n",
      "import numpy as np\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm = clas.Classifier()\n",
      "svm.create_training_data()\n",
      "#svm.train()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scorings = ['accuracy', \n",
      "            'average_precision',\n",
      "            'f1', 'f1_macro', 'f1_micro', 'f1_weighted',\n",
      "            'neg_log_loss',          \n",
      "            'precision', \n",
      "            'precision_macro',\n",
      "            'precision_micro',\n",
      "            'precision_weighted', \n",
      "            'recall', 'recall_macro', 'recall_micro', 'recall_weighted',\n",
      "            'roc_auc'\n",
      "            ]\n",
      "\n",
      "clustering = ['adjusted_mutual_info_score',\n",
      "              'adjusted_rand_score',\n",
      "              'completeness_score',\n",
      "              'fowlkes_mallows_score',\n",
      "              'homogeneity_score',\n",
      "              'mutual_info_score',\n",
      "              'normalized_mutual_info_score',\n",
      "              'neg_log_loss',\n",
      "              'v_measure_score']\n",
      "\n",
      "regression = ['explained_variance',\n",
      "              'neg_mean_absolute_error',\n",
      "              'neg_mean_squared_error',\n",
      "              'neg_mean_squared_log_error',\n",
      "              'neg_median_absolute_error',\n",
      "              'r2']\n",
      "\n",
      "multilabel_only = ['f1_samples', 'precision_samples', 'recall_samples']\n",
      "#scorings=['accuracy', 'average_precision']\n",
      "scorings = [\"accuracy\", \"precision\", \"recall\", \"f1\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#svm.evaluate(mode=\"train\", cv_scorings=scorings)\n",
      "#svm.extractor.n_negative_patches *= 3\n",
      "#svm.cross_validation(cv_scorings=scorings, extract_new_features=bool(0))\n",
      "svm.evaluate_test(to_train=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print svm.test_classifier.predict(svm.data)\n",
      "print svm.labels\n",
      "\n",
      "TP = 7.0\n",
      "FP = 5.0\n",
      "FN = 2.0\n",
      "print TP / (TP+FP) \n",
      "print TP / (TP+FN) \n",
      "\n",
      "print 1 - float( np.sum(svm.test_classifier.predict(svm.data) != svm.labels)) / len(svm.data)\n",
      "#print cross_val_score(svm.test_classifier, svm.data, svm.labels)\n",
      "\n",
      "print svm.test_classifier.score(svm.data, svm.labels)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.zeros(9)\n",
      "print a\n",
      "print a.reshape(1,-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.dataset.create_dataset_CT()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.extractor.extract_feature_vects(multiple_rois=False, \n",
      "                                     save_features=False,\n",
      "                                     mode=\"transform\")\n",
      "svm.create_training_data()\n",
      "print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.create_training_data(features=svm.extractor.features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.store_results()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(svm.dataset.orig_images)\n",
      "print svm.extractor.n_negatives\n",
      "print svm.extractor.n_negative_patches\n",
      "print len(svm.extractor.features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.extractor.features = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "clf = SVC(kernel=\"linear\", C = 0.1, probability=True, random_state=42)\n",
      "#clas.cross_val_score(clf, svm.data, svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cross_validate(clf, svm.data, svm.labels, scoring=scorings)#, return_train_score=False)\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"accuracy\")\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"precision\")\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"recall\")\n",
      "print cross_val_score(clf, svm.data, svm.labels, scoring=\"f1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(svm.data, svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = clf.predict(svm.data), svm.labels\n",
      "print confusion_matrix(yref, ypred)\n",
      "print classification_report(ypred, yref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = svm.test_classifier.predict(svm.data), svm.labels\n",
      "print confusion_matrix(yref, ypred)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = svm.test_classifier.predict(svm.data), svm.labels\n",
      "print accuracy_score(svm.test_classifier.predict(svm.data), svm.labels)\n",
      "a = classification_report(svm.test_classifier.predict(svm.data), svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(a)\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = clf.predict(svm.data), svm.labels\n",
      "print accuracy_score(clf.predict(svm.data), svm.labels)\n",
      "a = classification_report(clf.predict(svm.data), svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.test_classifier = copy.copy(clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import fbeta_score, make_scorer, precision_recall_fscore_support\n",
      "scorer = make_scorer(\"accuracy\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print precision_recall_fscore_support(ypred, yref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import recall_score\n",
      "print recall_score(ypred, yref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print recall_score.__name__+\"__pll\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print svm.data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ypred, yref = clf.predict(svm.data), svm.labels\n",
      "print accuracy_score(clf.predict(svm.data), svm.labels)\n",
      "print classification_report(clf.predict(svm.data), svm.labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Prohlizeni evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import data_reader as dr\n",
      "import file_manager as fm\n",
      "import copy\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "\n",
      "eval_path = \"extractor_test_results/HoG/evaluation/\"\n",
      "eval_path = \"extractor_test_results/2017-10-09__13-31-19-696000-classic/evaluation/\"\n",
      "eval_path = \"extractor_test_results/2017-10-09__20-47-04-898000-jako_vyse_ale_cv=5/evaluation/\"\n",
      "evals = [eval_path + imgname for imgname in os.listdir(eval_path) if imgname.endswith('.json') and not ('AFFINE' in imgname)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = list()\n",
      "\n",
      "for eval_file in evals:\n",
      "    scores.append(dr.load_json(eval_file))\n",
      "    scores[-1][\"name\"] = fm.get_imagename(eval_file)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = dict()\n",
      "test_keys = [key for key in scores[0].keys() if \"test\" in key]\n",
      "\n",
      "for key in test_keys:\n",
      "    best[key] = list()\n",
      "    sorted_scores = sorted(scores, key=lambda k: np.mean(k[key]))[::-1]\n",
      "    for score in sorted_scores:\n",
      "        best[key].append((score[\"name\"], np.mean(score[key])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_best(mode=\"best\", n_best=5):\n",
      "    scorings = test_keys\n",
      "    if n_best == -1:\n",
      "        n_best = len(best[scorings[0]])+1\n",
      "        \n",
      "    for scoring in scorings:\n",
      "        if mode == \"worst\":\n",
      "            print \"Nejhorsi podle \"+scoring+\": \"\n",
      "            for each in best[scoring][::-1][:n_best]:\n",
      "                print each\n",
      "        else:\n",
      "            print \"Nejlepsi podle \"+scoring+\": \"\n",
      "            for each in best[scoring][:n_best]:\n",
      "                print each"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_best(mode=\"wors\", n_best=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name = 'extracted_features_CV_ori=8_ppc=8_cpb=4_colored'\n",
      "ppc = re.findall(r'ppc\\=\\d+', name)[0]\n",
      "ppc = int(re.findall(r'\\d+', ppc)[0])\n",
      "\n",
      "ppcs = dict()\n",
      "cpbs = dict()\n",
      "oris = dict()\n",
      "\n",
      "keys = [\"test_accuracy\"]\n",
      "keys = [\"test_recall\"]\n",
      "#keys = [\"test_precision\"]\n",
      "#keys = best.keys()\n",
      "\n",
      "for scoring in keys:\n",
      "    for i, (name, value) in enumerate(best[scoring]):\n",
      "        \n",
      "        ppc = re.findall(r'ppc\\=\\d+', name)[0]\n",
      "        ppc = int(re.findall(r'\\d+', ppc)[0])\n",
      "        cpb = re.findall(r'cpb\\=\\d+', name)[0]\n",
      "        cpb = int(re.findall(r'\\d+', cpb)[0])\n",
      "        ori = re.findall(r'ori\\=\\d+', name)[0]\n",
      "        ori = int(re.findall(r'\\d+', ori)[0])\n",
      "        \n",
      "        #if not ori = 16:\n",
      "         #   continue\n",
      "        \n",
      "        if not ppcs.has_key(ppc):\n",
      "            ppcs[ppc] = 0\n",
      "        else:\n",
      "            ppcs[ppc] += i\n",
      "\n",
      "        if not cpbs.has_key(cpb):\n",
      "            cpbs[cpb] = 0\n",
      "        else:\n",
      "            cpbs[cpb] += i  \n",
      "\n",
      "        if not oris.has_key(ori):\n",
      "            oris[ori] = 0\n",
      "        else:\n",
      "            oris[ori] += i\n",
      "            \n",
      "print len(best[best.keys()[0]])        \n",
      "print oris\n",
      "print ppcs\n",
      "print cpbs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import OrderedDict\n",
      "\n",
      "oris_sorted_by_value = OrderedDict(sorted(oris.items(), key=lambda x: x[1]))\n",
      "ppcs_sorted_by_value = OrderedDict(sorted(ppcs.items(), key=lambda x: x[1]))\n",
      "cpbs_sorted_by_value = OrderedDict(sorted(cpbs.items(), key=lambda x: x[1]))\n",
      "\n",
      "print keys\n",
      "print \"ori: \", oris_sorted_by_value\n",
      "print \"ppc: \", ppcs_sorted_by_value\n",
      "print \"cpb: \", cpbs_sorted_by_value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# u medianu nejlepsi 16, 8, 3\n",
      "# u bilatelar: recall nejhorsi: 1\n",
      "#              precision nejhorsi: 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test vsech konfiguraci"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import data_reader as dr\n",
      "import file_manager as fm\n",
      "import copy\n",
      "import numpy as np\n",
      "import os\n",
      "import re\n",
      "import os.path as op\n",
      "from collections import OrderedDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "irelevant = [\"Bilateral\", \"Bilatelar\", \"HoG\", \"Median\", \"negatives\", \"Orig\", \"positives\", \"All\"]\n",
      "\n",
      "folders = [each for each in os.listdir(\"extractor_test_results\") if not (op.isfile(each) or each in irelevant)]\n",
      "folders48 = [each for each in os.listdir(\"extractor_test_results\") if \"48\" in each and \"Coloring2\" in each and not (op.isfile(each) or each in irelevant)]\n",
      "folders54 = [each for each in os.listdir(\"extractor_test_results\") if \"48\" not in each and \"Coloring2\" in each and not (op.isfile(each) or each in irelevant)]\n",
      "\n",
      "#folders = folders54\n",
      "\n",
      "evaluations = list()\n",
      "\n",
      "oris, ppcs, cpbs = {}, {}, {}\n",
      "\n",
      "for folder in folders:\n",
      "    evalpath = \"extractor_test_results/\" + folder + \"/evaluation/\"\n",
      "    for evalname in os.listdir(evalpath):\n",
      "        evaluation = (evalpath + evalname, dr.load_json(evalpath + evalname))\n",
      "        evaluations.append(evaluation)\n",
      "        name = evalname\n",
      "        ppc = re.findall(r'ppc\\=\\d+', name)[0]\n",
      "        ppc = int(re.findall(r'\\d+', ppc)[0])\n",
      "        cpb = re.findall(r'cpb\\=\\d+', name)[0]\n",
      "        cpb = int(re.findall(r'\\d+', cpb)[0])\n",
      "        ori = re.findall(r'ori\\=\\d+', name)[0]\n",
      "        ori = int(re.findall(r'\\d+', ori)[0])\n",
      "        \n",
      "        if not oris.has_key(ori):\n",
      "            oris[ori] = [np.mean(evaluation[1][\"recall\"])]\n",
      "        else:\n",
      "            oris[ori].append(np.mean(evaluation[1][\"recall\"]))\n",
      "            \n",
      "        if not ppcs.has_key(ppc):\n",
      "            ppcs[ppc] = [np.mean(evaluation[1][\"recall\"])]\n",
      "        else:\n",
      "            ppcs[ppc].append(np.mean(evaluation[1][\"recall\"]))\n",
      "            \n",
      "        if not cpbs.has_key(cpb):\n",
      "            cpbs[cpb] = [np.mean(evaluation[1][\"recall\"])]\n",
      "        else:\n",
      "            cpbs[cpb].append(np.mean(evaluation[1][\"recall\"]))\n",
      "        \n",
      "#print oris\n",
      "#print ppcs\n",
      "#print cpbs\n",
      "print len(evaluations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1120\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Serazeni podle prumeru u jednotlivych HoG parametru"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_ppc(name):\n",
      "    ppc = re.findall(r'ppc\\=\\d+', name)[0]\n",
      "    ppc = int(re.findall(r'\\d+', ppc)[0])\n",
      "    return ppc\n",
      "def find_cpb(name):\n",
      "    cpb = re.findall(r'cpb\\=\\d+', name)[0]\n",
      "    cpb = int(re.findall(r'\\d+', cpb)[0])\n",
      "    return cpb\n",
      "def find_ori(name):\n",
      "    ori = re.findall(r'ori\\=\\d+', name)[0]\n",
      "    ori = int(re.findall(r'\\d+', ori)[0])\n",
      "    return ori"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ori_avg_recalls = {}\n",
      "for ori, value in oris.items():\n",
      "    ori_avg_recalls[ori] = np.mean(value)\n",
      "    \n",
      "ppc_avg_recalls = {}\n",
      "for ppc, value in ppcs.items():\n",
      "    ppc_avg_recalls[ppc] = np.mean(value)\n",
      "    \n",
      "cpb_avg_recalls = {}\n",
      "for cpb, value in cpbs.items():\n",
      "    cpb_avg_recalls[cpb] = np.mean(value)\n",
      "\n",
      "print ori_avg_recalls\n",
      "print ppc_avg_recalls\n",
      "print cpb_avg_recalls\n",
      "\n",
      "oris_sorted_by_value = OrderedDict(sorted(ori_avg_recalls.items(), key=lambda x: -x[1]))\n",
      "ppcs_sorted_by_value = OrderedDict(sorted(ppc_avg_recalls.items(), key=lambda x: -x[1]))\n",
      "cpbs_sorted_by_value = OrderedDict(sorted(cpb_avg_recalls.items(), key=lambda x: -x[1]))\n",
      "\n",
      "print \"ori: \", oris_sorted_by_value\n",
      "print \"ppc: \", ppcs_sorted_by_value\n",
      "print \"cpb: \", cpbs_sorted_by_value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{9: 0.89235555760608032, 12: 0.89468690348365532, 6: 0.8888858985400262}\n",
        "{8: 0.89160868237824453, 10: 0.87452496172353456, 4: 0.90107626927493434, 6: 0.90140449566200054}\n",
        "{1: 0.9022292623578303, 2: 0.89223423488079623, 3: 0.88026285865545217}\n",
        "ori:  OrderedDict([(12, 0.89468690348365532), (9, 0.89235555760608032), (6, 0.8888858985400262)])\n",
        "ppc:  OrderedDict([(6, 0.90140449566200054), (4, 0.90107626927493434), (8, 0.89160868237824453), (10, 0.87452496172353456)])\n",
        "cpb:  OrderedDict([(1, 0.9022292623578303), (2, 0.89223423488079623), (3, 0.88026285865545217)])\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Vypis prvnich nekolik serazenych konfiguraci"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recalls = {}\n",
      "\n",
      "for conf, value in evaluations:\n",
      "    recalls[conf] = np.mean(value[\"recall\"])\n",
      "\n",
      "ordered = OrderedDict(sorted(recalls.items(), key=lambda x: -x[1]))\n",
      "\n",
      "noris = {}\n",
      "nppcs = {}\n",
      "ncpbs = {}\n",
      "\n",
      "for key1, value in ordered.items()[:]:\n",
      "    key2 = re.sub(\"extractor\\_test\\_results\\/[\\d\\-\\_]+\", \"\", key1)\n",
      "    key3 = re.sub(\"evaluation\", \"\", key2)\n",
      "    key = re.findall(\"ori\\=\\d+\\_+ppc\\=\\d+\\_+cpb=\\d+\", key3)[0]\n",
      "    #print key ,\"....\", value\n",
      "    #if find_ori(key) < 10:\n",
      "    #    print \"\",\n",
      "    print find_ori(key), find_ppc(key), find_cpb(key), \" ..... \", value\n",
      "    #print key3, \" .... \", value\n",
      "    \n",
      "    if noris.has_key(find_ori(key)):\n",
      "        noris[find_ori(key)] += 1\n",
      "    else:\n",
      "        noris[find_ori(key)] = 0\n",
      "    \n",
      "    if nppcs.has_key(find_ppc(key)):\n",
      "        nppcs[find_ppc(key)] += 1\n",
      "    else:\n",
      "        nppcs[find_ppc(key)] = 0\n",
      "\n",
      "    if ncpbs.has_key(find_cpb(key)):\n",
      "        ncpbs[find_cpb(key)] += 1\n",
      "    else:\n",
      "        ncpbs[find_cpb(key)] = 0\n",
      "    \n",
      "\n",
      "print OrderedDict(sorted(noris.items(), key=lambda x: -x[1]))\n",
      "print OrderedDict(sorted(nppcs.items(), key=lambda x: -x[1]))\n",
      "print OrderedDict(sorted(ncpbs.items(), key=lambda x: -x[1]))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9 4 2  .....  0.943569553806\n",
        "12 4 1  .....  0.941601049869\n",
        "9 4 1  .....  0.941272965879\n",
        "6 4 1  .....  0.940780839895\n",
        "6 4 1  .....  0.940780839895\n",
        "12 4 2  .....  0.9406167979\n",
        "9 6 2  .....  0.9406167979\n",
        "6 4 2  .....  0.9406167979\n",
        "12 4 2  .....  0.9406167979\n",
        "6 4 1  .....  0.940452755906\n",
        "9 4 2  .....  0.940452755906\n",
        "9 6 2  .....  0.940124671916\n",
        "9 6 1  .....  0.939960629921\n",
        "9 6 2  .....  0.939796587927\n",
        "9 4 3  .....  0.939796587927\n",
        "6 4 2  .....  0.939632545932\n",
        "6 4 2  .....  0.939632545932\n",
        "9 4 1  .....  0.939632545932\n",
        "12 6 2  .....  0.939468503937\n",
        "9 4 1  .....  0.939468503937\n",
        "12 4 1  .....  0.939468503937\n",
        "9 4 3  .....  0.939304461942\n",
        "9 4 1  .....  0.939304461942\n",
        "12 6 2  .....  0.939140419948\n",
        "6 6 2  .....  0.939140419948\n",
        "6 4 2  .....  0.939140419948\n",
        "12 6 2  .....  0.938976377953\n",
        "6 4 3  .....  0.938976377953\n",
        "12 4 2  .....  0.938812335958\n",
        "9 4 2  .....  0.938812335958\n",
        "6 4 2  .....  0.938648293963\n",
        "12 4 2  .....  0.938320209974\n",
        "9 6 1  .....  0.938320209974\n",
        "6 4 1  .....  0.938320209974\n",
        "9 4 1  .....  0.938156167979\n",
        "12 6 1  .....  0.93782808399\n",
        "9 4 2  .....  0.93782808399\n",
        "9 6 2  .....  0.93782808399\n",
        "9 4 2  .....  0.9375\n",
        "9 4 2  .....  0.9375\n",
        "6 4 3  .....  0.937335958005\n",
        "6 6 2  .....  0.93717191601\n",
        "6 4 2  .....  0.93717191601\n",
        "6 6 2  .....  0.936843832021\n",
        "12 4 1  .....  0.936515748031\n",
        "12 6 2  .....  0.936351706037\n",
        "9 4 1  .....  0.936187664042\n",
        "9 6 1  .....  0.935859580052\n",
        "9 4 1  .....  0.935203412073\n",
        "6 6 2  .....  0.934711286089\n",
        "9 4 3  .....  0.934711286089\n",
        "12 6 1  .....  0.9343832021\n",
        "6 6 1  .....  0.934219160105\n",
        "6 4 3  .....  0.934219160105\n",
        "12 4 1  .....  0.93405511811\n",
        "6 4 3  .....  0.933891076115\n",
        "9 4 3  .....  0.933727034121\n",
        "12 4 1  .....  0.933562992126\n",
        "12 6 1  .....  0.933398950131\n",
        "12 4 1  .....  0.932578740157\n",
        "9 6 1  .....  0.932578740157\n",
        "9 6 2  .....  0.932250656168\n",
        "12 4 2  .....  0.931922572178\n",
        "6 4 1  .....  0.931922572178\n",
        "9 6 2  .....  0.931430446194\n",
        "9 4 1  .....  0.931266404199\n",
        "12 4 2  .....  0.931102362205\n",
        "12 4 1  .....  0.93093832021\n",
        "9 6 1  .....  0.93093832021\n",
        "6 8 2  .....  0.930774278215\n",
        "9 4 1  .....  0.930282152231\n",
        "12 8 2  .....  0.930118110236\n",
        "9 6 1  .....  0.929954068241\n",
        "6 6 2  .....  0.929625984252\n",
        "9 6 2  .....  0.929625984252\n",
        "9 8 2  .....  0.929461942257\n",
        "12 8 2  .....  0.929461942257\n",
        "12 4 1  .....  0.929133858268\n",
        "9 6 3  .....  0.928969816273\n",
        "6 6 3  .....  0.928969816273\n",
        "9 4 1  .....  0.928805774278\n",
        "12 6 3  .....  0.928641732283\n",
        "6 6 3  .....  0.928641732283\n",
        "9 6 3  .....  0.928477690289\n",
        "12 6 1  .....  0.928477690289\n",
        "9 8 2  .....  0.928313648294\n",
        "12 6 3  .....  0.92782152231\n",
        "9 6 1  .....  0.927657480315\n",
        "6 6 2  .....  0.92749343832\n",
        "6 8 2  .....  0.92749343832\n",
        "12 6 1  .....  0.927329396325\n",
        "12 6 2  .....  0.926837270341\n",
        "12 4 1  .....  0.926837270341\n",
        "9 6 1  .....  0.926509186352\n",
        "6 6 2  .....  0.926509186352\n",
        "9 6 2  .....  0.926509186352\n",
        "12 4 1  .....  0.926181102362\n",
        "9 4 1  .....  0.926017060367\n",
        "6 4 1  .....  0.926017060367\n",
        "9 6 3  .....  0.926017060367\n",
        "9 4 3  .....  0.926017060367\n",
        "6 6 3  .....  0.925853018373\n",
        "12 4 1  .....  0.925853018373\n",
        "6 6 1  .....  0.925688976378\n",
        "9 4 2  .....  0.925688976378\n",
        "9 6 2  .....  0.925524934383\n",
        "12 6 3  .....  0.925360892388\n",
        "9 4 2  .....  0.925360892388\n",
        "12 4 2  .....  0.925196850394\n",
        "12 6 1  .....  0.925196850394\n",
        "12 6 1  .....  0.925196850394\n",
        "9 6 1  .....  0.925196850394\n",
        "12 6 2  .....  0.925196850394\n",
        "12 4 1  .....  0.925032808399\n",
        "6 4 3  .....  0.924868766404\n",
        "6 6 2  .....  0.924868766404\n",
        "9 4 1  .....  0.924704724409\n",
        "9 4 1  .....  0.924704724409\n",
        "9 6 1  .....  0.924212598425\n",
        "9 4 1  .....  0.924212598425\n",
        "12 8 2  .....  0.924212598425\n",
        "12 6 3  .....  0.92404855643\n",
        "9 4 3  .....  0.92404855643\n",
        "12 8 1  .....  0.92404855643\n",
        "9 8 1  .....  0.923884514436\n",
        "9 6 2  .....  0.923884514436\n",
        "9 4 1  .....  0.923884514436\n",
        "9 4 3  .....  0.923720472441\n",
        "12 6 2  .....  0.923556430446\n",
        "12 6 1  .....  0.923556430446\n",
        "6 6 3  .....  0.923556430446\n",
        "9 4 1  .....  0.923556430446\n",
        "12 4 2  .....  0.923392388451\n",
        "12 6 1  .....  0.923392388451\n",
        "9 4 2  .....  0.923392388451\n",
        "12 6 1  .....  0.923228346457\n",
        "9 6 3  .....  0.923228346457\n",
        "6 4 2  .....  0.923228346457\n",
        "6 6 2  .....  0.923228346457\n",
        "12 6 2  .....  0.923228346457\n",
        "12 8 1  .....  0.923064304462\n",
        "12 6 1  .....  0.923064304462\n",
        "6 4 3  .....  0.923064304462\n",
        "12 6 1  .....  0.923064304462\n",
        "9 4 2  .....  0.922900262467\n",
        "9 6 3  .....  0.922900262467\n",
        "6 4 3  .....  0.922736220472\n",
        "12 8 2  .....  0.922572178478\n",
        "6 6 1  .....  0.922572178478\n",
        "6 4 2  .....  0.922408136483\n",
        "12 6 2  .....  0.922408136483\n",
        "12 4 1  .....  0.922244094488\n",
        "6 4 1  .....  0.922244094488\n",
        "9 4 3  .....  0.922244094488\n",
        "6 4 1  .....  0.922244094488\n",
        "9 8 2  .....  0.922244094488\n",
        "12 6 3  .....  0.922080052493\n",
        "9 4 1  .....  0.922080052493\n",
        "6 4 3  .....  0.921916010499\n",
        "12 4 1  .....  0.921916010499\n",
        "6 6 3  .....  0.921751968504\n",
        "6 4 1  .....  0.921751968504\n",
        "9 8 2  .....  0.921751968504\n",
        "6 4 1  .....  0.921751968504\n",
        "9 6 1  .....  0.921587926509\n",
        "9 8 1  .....  0.921587926509\n",
        "9 4 1  .....  0.921423884514\n",
        "12 6 1  .....  0.921423884514\n",
        "12 6 3  .....  0.921095800525\n",
        "12 4 2  .....  0.921095800525\n",
        "12 8 1  .....  0.921095800525\n",
        "9 4 2  .....  0.92093175853\n",
        "6 6 2  .....  0.92093175853\n",
        "9 4 1  .....  0.920767716535\n",
        "12 8 3  .....  0.920603674541\n",
        "6 4 2  .....  0.920603674541\n",
        "12 6 1  .....  0.920439632546\n",
        "12 8 3  .....  0.920439632546\n",
        "9 4 1  .....  0.920275590551\n",
        "9 8 1  .....  0.920275590551\n",
        "9 6 3  .....  0.920111548556\n",
        "9 4 1  .....  0.920111548556\n",
        "6 4 1  .....  0.920111548556\n",
        "12 4 1  .....  0.919947506562\n",
        "12 10 2  .....  0.919947506562\n",
        "6 6 2  .....  0.919783464567\n",
        "6 6 3  .....  0.919619422572\n",
        "9 6 1  .....  0.919619422572\n",
        "9 6 1  .....  0.919619422572\n",
        "12 4 1  .....  0.919619422572\n",
        "12 6 2  .....  0.919455380577\n",
        "6 6 1  .....  0.919455380577\n",
        "9 8 3  .....  0.919455380577\n",
        "6 6 1  .....  0.919291338583\n",
        "9 6 1  .....  0.919291338583\n",
        "9 4 1  .....  0.919291338583\n",
        "9 6 1  .....  0.919127296588\n",
        "6 8 3  .....  0.919127296588\n",
        "12 4 2  .....  0.919127296588\n",
        "12 4 1  .....  0.918963254593\n",
        "6 6 1  .....  0.918963254593\n",
        "6 6 1  .....  0.918963254593\n",
        "6 4 2  .....  0.918963254593\n",
        "12 8 1  .....  0.918963254593\n",
        "12 8 1  .....  0.918799212598\n",
        "9 6 3  .....  0.918799212598\n",
        "9 8 3  .....  0.918799212598\n",
        "12 6 3  .....  0.918635170604\n",
        "12 8 1  .....  0.918635170604\n",
        "9 4 1  .....  0.918635170604\n",
        "12 6 1  .....  0.918471128609\n",
        "9 6 1  .....  0.918471128609\n",
        "9 4 3  .....  0.918471128609\n",
        "9 8 1  .....  0.918471128609\n",
        "9 6 3  .....  0.918471128609\n",
        "9 4 2  .....  0.918307086614\n",
        "9 6 1  .....  0.918307086614\n",
        "12 4 1  .....  0.918307086614\n",
        "6 6 3  .....  0.918307086614\n",
        "9 6 1  .....  0.918143044619\n",
        "9 8 1  .....  0.918143044619\n",
        "12 10 2  .....  0.918143044619\n",
        "12 8 2  .....  0.918143044619\n",
        "12 8 3  .....  0.917979002625\n",
        "9 8 1  .....  0.917979002625\n",
        "6 4 3  .....  0.91781496063\n",
        "6 4 1  .....  0.91781496063\n",
        "12 6 3  .....  0.91781496063\n",
        "9 4 3  .....  0.91781496063\n",
        "12 4 1  .....  0.917650918635\n",
        "6 4 1  .....  0.917650918635\n",
        "9 6 2  .....  0.917650918635\n",
        "12 4 1  .....  0.917650918635\n",
        "12 4 1  .....  0.91748687664\n",
        "9 8 2  .....  0.91748687664\n",
        "9 8 1  .....  0.91748687664\n",
        "12 6 2  .....  0.91748687664\n",
        "12 8 2  .....  0.91748687664\n",
        "6 8 3  .....  0.91748687664\n",
        "9 8 1  .....  0.91748687664\n",
        "12 4 2  .....  0.91748687664\n",
        "9 10 2  .....  0.917322834646\n",
        "6 6 3  .....  0.917322834646\n",
        "12 6 1  .....  0.917322834646\n",
        "12 6 1  .....  0.917322834646\n",
        "9 6 1  .....  0.917322834646\n",
        "12 4 1  .....  0.917322834646\n",
        "9 8 3  .....  0.917322834646\n",
        "12 6 1  .....  0.917158792651\n",
        "6 4 3  .....  0.917158792651\n",
        "9 8 3  .....  0.917158792651\n",
        "9 4 3  .....  0.917158792651\n",
        "6 4 1  .....  0.917158792651\n",
        "12 8 1  .....  0.916994750656\n",
        "9 10 2  .....  0.916994750656\n",
        "6 4 3  .....  0.916994750656\n",
        "12 10 1  .....  0.916994750656\n",
        "12 8 1  .....  0.916830708661\n",
        "9 4 2  .....  0.916666666667\n",
        "12 6 2  .....  0.916666666667\n",
        "12 10 1  .....  0.916666666667\n",
        "9 6 1  .....  0.916666666667\n",
        "12 6 2  .....  0.916502624672\n",
        "9 8 1  .....  0.916502624672\n",
        "9 10 1  .....  0.916502624672\n",
        "12 10 1  .....  0.916502624672\n",
        "6 4 1  .....  0.916502624672\n",
        "12 8 1  .....  0.916338582677\n",
        "9 6 2  .....  0.916174540682\n",
        "12 10 3  .....  0.916010498688\n",
        "9 8 2  .....  0.916010498688\n",
        "9 8 2  .....  0.915846456693\n",
        "9 6 1  .....  0.915846456693\n",
        "9 8 2  .....  0.915682414698\n",
        "6 8 2  .....  0.915518372703\n",
        "9 6 3  .....  0.915518372703\n",
        "6 4 1  .....  0.915518372703\n",
        "12 8 3  .....  0.915354330709\n",
        "12 4 2  .....  0.915190288714\n",
        "6 6 2  .....  0.915190288714\n",
        "9 6 1  .....  0.915190288714\n",
        "12 6 1  .....  0.915190288714\n",
        "12 6 1  .....  0.915190288714\n",
        "6 4 3  .....  0.915026246719\n",
        "6 6 3  .....  0.915026246719\n",
        "9 4 1  .....  0.91469816273\n",
        "12 8 3  .....  0.91469816273\n",
        "12 8 3  .....  0.91469816273\n",
        "6 8 2  .....  0.91469816273\n",
        "12 8 2  .....  0.914534120735\n",
        "6 6 1  .....  0.914534120735\n",
        "9 8 1  .....  0.914534120735\n",
        "12 10 3  .....  0.91437007874\n",
        "9 10 1  .....  0.91437007874\n",
        "6 6 2  .....  0.91437007874\n",
        "9 10 1  .....  0.91437007874\n",
        "12 6 3  .....  0.91437007874\n",
        "9 6 3  .....  0.91437007874\n",
        "6 8 2  .....  0.914206036745\n",
        "6 4 2  .....  0.914206036745\n",
        "12 6 1  .....  0.914041994751\n",
        "6 6 3  .....  0.914041994751\n",
        "12 8 1  .....  0.914041994751\n",
        "12 4 1  .....  0.914041994751\n",
        "9 8 3  .....  0.913877952756\n",
        "6 6 3  .....  0.913877952756\n",
        "12 4 1  .....  0.913877952756\n",
        "12 8 1  .....  0.913549868766\n",
        "9 4 1  .....  0.913549868766\n",
        "6 6 1  .....  0.913549868766\n",
        "6 4 1  .....  0.913385826772\n",
        "12 6 1  .....  0.913385826772\n",
        "9 6 2  .....  0.913385826772\n",
        "6 8 3  .....  0.913221784777\n",
        "6 4 1  .....  0.913221784777\n",
        "12 6 1  .....  0.913221784777\n",
        "12 8 2  .....  0.913221784777\n",
        "9 8 2  .....  0.913221784777\n",
        "6 4 1  .....  0.913221784777\n",
        "12 6 3  .....  0.913057742782\n",
        "12 8 1  .....  0.913057742782\n",
        "6 4 2  .....  0.912893700787\n",
        "9 8 3  .....  0.912729658793\n",
        "6 8 3  .....  0.912729658793\n",
        "6 6 2  .....  0.912565616798\n",
        "9 8 1  .....  0.912401574803\n",
        "12 8 3  .....  0.912401574803\n",
        "6 8 2  .....  0.912401574803\n",
        "9 8 2  .....  0.912401574803\n",
        "9 4 3  .....  0.912237532808\n",
        "6 6 3  .....  0.912237532808\n",
        "9 8 2  .....  0.912237532808\n",
        "6 8 2  .....  0.912073490814\n",
        "6 8 1  .....  0.912073490814\n",
        "6 8 2  .....  0.911909448819\n",
        "6 8 2  .....  0.911909448819\n",
        "6 8 1  .....  0.911745406824\n",
        "6 8 1  .....  0.911581364829\n",
        "12 8 3  .....  0.911581364829\n",
        "12 6 1  .....  0.911581364829\n",
        "12 8 2  .....  0.911581364829\n",
        "6 8 3  .....  0.911581364829\n",
        "9 6 3  .....  0.911581364829\n",
        "12 6 2  .....  0.911581364829\n",
        "9 4 1  .....  0.911581364829\n",
        "12 4 1  .....  0.911581364829\n",
        "12 10 3  .....  0.911581364829\n",
        "6 4 1  .....  0.911417322835\n",
        "12 10 3  .....  0.911417322835\n",
        "9 6 2  .....  0.911417322835\n",
        "12 8 1  .....  0.911417322835\n",
        "6 8 2  .....  0.911417322835\n",
        "9 8 1  .....  0.91125328084\n",
        "9 4 3  .....  0.91125328084\n",
        "6 6 1  .....  0.91125328084\n",
        "9 8 1  .....  0.91125328084\n",
        "12 10 1  .....  0.911089238845\n",
        "12 4 1  .....  0.911089238845\n",
        "12 6 3  .....  0.911089238845\n",
        "6 6 1  .....  0.911089238845\n",
        "9 8 1  .....  0.911089238845\n",
        "12 4 2  .....  0.91092519685\n",
        "12 8 2  .....  0.91092519685\n",
        "6 8 1  .....  0.91092519685\n",
        "6 8 3  .....  0.91092519685\n",
        "9 6 2  .....  0.91092519685\n",
        "6 6 1  .....  0.910597112861\n",
        "12 4 2  .....  0.910597112861\n",
        "9 6 3  .....  0.910433070866\n",
        "6 10 2  .....  0.910433070866\n",
        "6 10 1  .....  0.910433070866\n",
        "9 8 3  .....  0.910269028871\n",
        "6 4 3  .....  0.910269028871\n",
        "12 10 2  .....  0.910104986877\n",
        "9 8 2  .....  0.910104986877\n",
        "9 10 1  .....  0.910104986877\n",
        "6 6 3  .....  0.910104986877\n",
        "12 8 1  .....  0.910104986877\n",
        "12 10 1  .....  0.910104986877\n",
        "6 6 2  .....  0.909940944882\n",
        "9 6 3  .....  0.909940944882\n",
        "6 10 2  .....  0.909940944882\n",
        "6 8 2  .....  0.909776902887\n",
        "9 6 1  .....  0.909776902887\n",
        "9 10 2  .....  0.909612860892\n",
        "12 10 1  .....  0.909612860892\n",
        "12 8 2  .....  0.909612860892\n",
        "12 8 1  .....  0.909612860892\n",
        "12 10 2  .....  0.909612860892\n",
        "12 8 1  .....  0.909612860892\n",
        "6 10 2  .....  0.909612860892\n",
        "6 10 1  .....  0.909448818898\n",
        "9 10 3  .....  0.909448818898\n",
        "9 10 2  .....  0.909284776903\n",
        "6 6 3  .....  0.909120734908\n",
        "12 6 3  .....  0.908792650919\n",
        "12 4 1  .....  0.908792650919\n",
        "9 8 1  .....  0.908792650919\n",
        "6 4 1  .....  0.908628608924\n",
        "9 8 3  .....  0.908628608924\n",
        "9 4 1  .....  0.908464566929\n",
        "9 8 1  .....  0.908300524934\n",
        "6 6 1  .....  0.90813648294\n",
        "9 4 3  .....  0.90813648294\n",
        "6 6 1  .....  0.90780839895\n",
        "6 4 1  .....  0.90780839895\n",
        "6 6 1  .....  0.907644356955\n",
        "6 10 2  .....  0.907644356955\n",
        "9 6 3  .....  0.907480314961\n",
        "9 10 1  .....  0.907480314961\n",
        "12 8 1  .....  0.907316272966\n",
        "12 8 1  .....  0.906988188976\n",
        "9 8 1  .....  0.906824146982\n",
        "6 6 1  .....  0.906824146982\n",
        "6 8 2  .....  0.906824146982\n",
        "6 8 1  .....  0.906496062992\n",
        "12 6 2  .....  0.906496062992\n",
        "9 4 2  .....  0.906332020997\n",
        "6 8 3  .....  0.906332020997\n",
        "12 6 1  .....  0.906332020997\n",
        "9 10 3  .....  0.906332020997\n",
        "12 8 2  .....  0.906167979003\n",
        "9 10 3  .....  0.906167979003\n",
        "6 4 2  .....  0.906167979003\n",
        "6 8 1  .....  0.906003937008\n",
        "6 6 2  .....  0.906003937008\n",
        "6 8 1  .....  0.905675853018\n",
        "6 4 3  .....  0.905675853018\n",
        "12 8 1  .....  0.905511811024\n",
        "6 10 1  .....  0.905511811024\n",
        "6 4 2  .....  0.905511811024\n",
        "12 10 2  .....  0.905183727034\n",
        "6 4 2  .....  0.905183727034\n",
        "9 10 3  .....  0.905019685039\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9 6 2  .....  0.905019685039\n",
        "9 10 1  .....  0.905019685039\n",
        "9 6 1  .....  0.905019685039\n",
        "9 4 2  .....  0.904855643045\n",
        "9 6 1  .....  0.904855643045\n",
        "12 8 3  .....  0.904527559055\n",
        "6 6 1  .....  0.904527559055\n",
        "12 8 3  .....  0.904527559055\n",
        "12 6 3  .....  0.904527559055\n",
        "6 8 3  .....  0.90436351706\n",
        "6 4 1  .....  0.90436351706\n",
        "12 6 3  .....  0.904199475066\n",
        "12 10 2  .....  0.904199475066\n",
        "12 10 1  .....  0.904035433071\n",
        "12 8 3  .....  0.903707349081\n",
        "12 8 1  .....  0.903707349081\n",
        "9 4 1  .....  0.903707349081\n",
        "6 8 1  .....  0.903707349081\n",
        "12 6 2  .....  0.903543307087\n",
        "6 6 1  .....  0.903543307087\n",
        "9 8 3  .....  0.903215223097\n",
        "9 6 1  .....  0.903215223097\n",
        "6 6 1  .....  0.902887139108\n",
        "9 10 1  .....  0.902887139108\n",
        "12 10 2  .....  0.902723097113\n",
        "12 10 1  .....  0.902230971129\n",
        "6 8 1  .....  0.902066929134\n",
        "9 10 2  .....  0.902066929134\n",
        "12 8 1  .....  0.901902887139\n",
        "9 4 2  .....  0.901738845144\n",
        "12 10 1  .....  0.901738845144\n",
        "9 10 2  .....  0.90157480315\n",
        "9 8 1  .....  0.90157480315\n",
        "12 10 2  .....  0.901410761155\n",
        "6 8 2  .....  0.901410761155\n",
        "12 8 2  .....  0.901410761155\n",
        "12 6 1  .....  0.90124671916\n",
        "6 8 1  .....  0.90124671916\n",
        "12 8 3  .....  0.90124671916\n",
        "9 10 1  .....  0.90124671916\n",
        "12 4 1  .....  0.901082677165\n",
        "9 8 3  .....  0.900918635171\n",
        "9 8 3  .....  0.900590551181\n",
        "9 6 1  .....  0.900426509186\n",
        "6 4 2  .....  0.900262467192\n",
        "9 10 2  .....  0.900098425197\n",
        "9 8 1  .....  0.899934383202\n",
        "9 10 2  .....  0.899934383202\n",
        "6 8 1  .....  0.899770341207\n",
        "6 8 3  .....  0.899442257218\n",
        "6 6 2  .....  0.899114173228\n",
        "12 6 1  .....  0.899114173228\n",
        "12 8 3  .....  0.898950131234\n",
        "12 6 2  .....  0.898950131234\n",
        "12 10 3  .....  0.898950131234\n",
        "9 10 1  .....  0.898786089239\n",
        "12 6 1  .....  0.898786089239\n",
        "9 10 1  .....  0.898786089239\n",
        "6 10 3  .....  0.898786089239\n",
        "12 10 1  .....  0.898622047244\n",
        "6 4 2  .....  0.898293963255\n",
        "6 10 2  .....  0.898293963255\n",
        "12 6 2  .....  0.898293963255\n",
        "9 8 1  .....  0.898293963255\n",
        "9 6 2  .....  0.89812992126\n",
        "12 6 3  .....  0.89812992126\n",
        "6 8 1  .....  0.897965879265\n",
        "12 4 1  .....  0.89780183727\n",
        "9 8 3  .....  0.89780183727\n",
        "6 10 3  .....  0.89780183727\n",
        "9 8 1  .....  0.897637795276\n",
        "6 10 1  .....  0.897637795276\n",
        "6 6 1  .....  0.897473753281\n",
        "6 8 1  .....  0.897473753281\n",
        "12 8 3  .....  0.897309711286\n",
        "12 10 2  .....  0.897309711286\n",
        "6 6 2  .....  0.897145669291\n",
        "6 10 3  .....  0.897145669291\n",
        "12 10 1  .....  0.897145669291\n",
        "6 8 1  .....  0.896981627297\n",
        "12 6 3  .....  0.896817585302\n",
        "12 4 2  .....  0.896817585302\n",
        "6 6 3  .....  0.896653543307\n",
        "12 6 2  .....  0.896653543307\n",
        "9 10 3  .....  0.896653543307\n",
        "6 6 2  .....  0.896653543307\n",
        "12 10 3  .....  0.896653543307\n",
        "6 6 3  .....  0.896653543307\n",
        "12 4 2  .....  0.896489501312\n",
        "9 8 1  .....  0.896489501312\n",
        "9 6 2  .....  0.896325459318\n",
        "12 8 1  .....  0.896325459318\n",
        "12 6 1  .....  0.896325459318\n",
        "12 10 3  .....  0.896161417323\n",
        "6 10 3  .....  0.896161417323\n",
        "9 8 2  .....  0.896161417323\n",
        "6 10 1  .....  0.896161417323\n",
        "12 10 2  .....  0.895997375328\n",
        "6 8 3  .....  0.895997375328\n",
        "12 4 1  .....  0.895997375328\n",
        "12 8 2  .....  0.895833333333\n",
        "6 8 2  .....  0.895833333333\n",
        "9 8 1  .....  0.895833333333\n",
        "12 10 3  .....  0.895669291339\n",
        "6 8 2  .....  0.895669291339\n",
        "6 6 1  .....  0.895669291339\n",
        "6 6 2  .....  0.895669291339\n",
        "12 10 1  .....  0.895669291339\n",
        "6 4 1  .....  0.895505249344\n",
        "6 4 2  .....  0.895505249344\n",
        "6 10 1  .....  0.895505249344\n",
        "12 6 1  .....  0.895505249344\n",
        "9 8 2  .....  0.895177165354\n",
        "12 10 2  .....  0.895177165354\n",
        "9 8 1  .....  0.89501312336\n",
        "12 6 3  .....  0.89501312336\n",
        "12 8 3  .....  0.89501312336\n",
        "9 10 2  .....  0.894849081365\n",
        "9 6 2  .....  0.894520997375\n",
        "6 4 3  .....  0.894356955381\n",
        "12 4 2  .....  0.894356955381\n",
        "9 10 3  .....  0.894192913386\n",
        "9 8 2  .....  0.894192913386\n",
        "6 10 2  .....  0.894192913386\n",
        "9 6 3  .....  0.894028871391\n",
        "12 8 2  .....  0.893864829396\n",
        "6 4 3  .....  0.893864829396\n",
        "6 6 2  .....  0.893864829396\n",
        "12 6 2  .....  0.893700787402\n",
        "12 10 2  .....  0.893700787402\n",
        "12 6 3  .....  0.893700787402\n",
        "6 4 1  .....  0.893536745407\n",
        "12 10 3  .....  0.893536745407\n",
        "9 6 1  .....  0.893372703412\n",
        "9 8 1  .....  0.893372703412\n",
        "9 10 1  .....  0.893372703412\n",
        "6 10 2  .....  0.893372703412\n",
        "6 8 2  .....  0.893208661417\n",
        "9 4 2  .....  0.893208661417\n",
        "9 8 3  .....  0.893208661417\n",
        "6 4 1  .....  0.893208661417\n",
        "9 6 3  .....  0.893044619423\n",
        "9 8 2  .....  0.892880577428\n",
        "6 4 2  .....  0.892880577428\n",
        "6 8 2  .....  0.892716535433\n",
        "6 4 2  .....  0.892716535433\n",
        "9 8 2  .....  0.892552493438\n",
        "12 6 1  .....  0.892552493438\n",
        "6 4 2  .....  0.892552493438\n",
        "6 6 1  .....  0.892552493438\n",
        "6 6 2  .....  0.892552493438\n",
        "9 8 3  .....  0.892552493438\n",
        "9 6 3  .....  0.892388451444\n",
        "6 6 3  .....  0.892388451444\n",
        "9 4 3  .....  0.892224409449\n",
        "12 8 3  .....  0.892224409449\n",
        "6 8 3  .....  0.892224409449\n",
        "6 10 3  .....  0.892224409449\n",
        "9 10 2  .....  0.892224409449\n",
        "12 8 1  .....  0.892060367454\n",
        "9 4 3  .....  0.892060367454\n",
        "6 8 3  .....  0.891896325459\n",
        "12 6 3  .....  0.891896325459\n",
        "6 6 3  .....  0.891896325459\n",
        "12 10 2  .....  0.891732283465\n",
        "6 10 2  .....  0.89156824147\n",
        "9 10 1  .....  0.89156824147\n",
        "9 6 2  .....  0.89156824147\n",
        "12 6 2  .....  0.89156824147\n",
        "9 6 1  .....  0.891404199475\n",
        "9 10 2  .....  0.891404199475\n",
        "12 10 3  .....  0.89124015748\n",
        "9 10 1  .....  0.89124015748\n",
        "12 8 2  .....  0.89124015748\n",
        "9 10 1  .....  0.89124015748\n",
        "6 10 2  .....  0.891076115486\n",
        "6 8 3  .....  0.891076115486\n",
        "12 8 1  .....  0.891076115486\n",
        "9 4 1  .....  0.891076115486\n",
        "12 8 1  .....  0.890912073491\n",
        "12 6 1  .....  0.890912073491\n",
        "6 6 1  .....  0.890748031496\n",
        "12 8 2  .....  0.890748031496\n",
        "6 10 1  .....  0.890748031496\n",
        "9 6 3  .....  0.890748031496\n",
        "9 6 1  .....  0.890748031496\n",
        "9 8 2  .....  0.890748031496\n",
        "6 10 2  .....  0.890583989501\n",
        "12 10 1  .....  0.890583989501\n",
        "9 6 2  .....  0.890419947507\n",
        "6 8 3  .....  0.890255905512\n",
        "9 10 1  .....  0.890091863517\n",
        "9 4 2  .....  0.890091863517\n",
        "9 4 1  .....  0.890091863517\n",
        "12 4 1  .....  0.889927821522\n",
        "12 10 1  .....  0.889763779528\n",
        "6 4 2  .....  0.889763779528\n",
        "6 6 1  .....  0.889763779528\n",
        "6 10 1  .....  0.889763779528\n",
        "12 6 2  .....  0.889763779528\n",
        "9 4 1  .....  0.889599737533\n",
        "9 10 3  .....  0.889599737533\n",
        "12 8 2  .....  0.889599737533\n",
        "9 6 3  .....  0.889599737533\n",
        "6 8 2  .....  0.889435695538\n",
        "12 8 2  .....  0.889435695538\n",
        "12 8 1  .....  0.889271653543\n",
        "12 8 1  .....  0.889271653543\n",
        "12 8 1  .....  0.889107611549\n",
        "9 10 2  .....  0.889107611549\n",
        "6 8 1  .....  0.888943569554\n",
        "9 4 2  .....  0.888943569554\n",
        "6 6 2  .....  0.888943569554\n",
        "12 10 2  .....  0.888943569554\n",
        "12 8 3  .....  0.888779527559\n",
        "6 10 1  .....  0.888779527559\n",
        "12 8 1  .....  0.888615485564\n",
        "6 10 2  .....  0.888615485564\n",
        "6 10 2  .....  0.88845144357\n",
        "12 6 2  .....  0.88845144357\n",
        "9 6 1  .....  0.888287401575\n",
        "6 8 2  .....  0.888287401575\n",
        "12 8 2  .....  0.888287401575\n",
        "6 8 1  .....  0.88812335958\n",
        "6 8 1  .....  0.887959317585\n",
        "6 8 2  .....  0.887959317585\n",
        "9 6 3  .....  0.887959317585\n",
        "9 6 2  .....  0.887795275591\n",
        "12 4 2  .....  0.887795275591\n",
        "6 6 1  .....  0.887631233596\n",
        "9 8 3  .....  0.887631233596\n",
        "12 4 2  .....  0.887631233596\n",
        "6 8 3  .....  0.887467191601\n",
        "9 8 3  .....  0.887467191601\n",
        "12 6 2  .....  0.887467191601\n",
        "6 10 2  .....  0.887303149606\n",
        "12 10 1  .....  0.887303149606\n",
        "6 8 3  .....  0.887303149606\n",
        "6 10 2  .....  0.887303149606\n",
        "12 6 3  .....  0.887139107612\n",
        "9 10 2  .....  0.887139107612\n",
        "9 10 2  .....  0.887139107612\n",
        "6 4 2  .....  0.887139107612\n",
        "6 8 1  .....  0.887139107612\n",
        "6 8 2  .....  0.886975065617\n",
        "12 10 1  .....  0.886975065617\n",
        "6 10 1  .....  0.886975065617\n",
        "6 8 2  .....  0.886811023622\n",
        "12 10 2  .....  0.886811023622\n",
        "12 10 2  .....  0.886646981627\n",
        "9 6 2  .....  0.886646981627\n",
        "9 8 2  .....  0.886482939633\n",
        "6 8 1  .....  0.886318897638\n",
        "12 6 3  .....  0.886318897638\n",
        "9 6 2  .....  0.885990813648\n",
        "6 8 3  .....  0.885990813648\n",
        "9 6 1  .....  0.885826771654\n",
        "6 6 1  .....  0.885662729659\n",
        "6 6 1  .....  0.885662729659\n",
        "6 8 3  .....  0.885662729659\n",
        "9 6 3  .....  0.885498687664\n",
        "12 10 2  .....  0.885334645669\n",
        "12 8 3  .....  0.885334645669\n",
        "6 8 3  .....  0.885334645669\n",
        "9 10 3  .....  0.885170603675\n",
        "12 10 1  .....  0.885170603675\n",
        "9 6 3  .....  0.885170603675\n",
        "9 6 2  .....  0.88500656168\n",
        "9 10 2  .....  0.88500656168\n",
        "12 8 2  .....  0.88500656168\n",
        "6 6 1  .....  0.88500656168\n",
        "9 6 2  .....  0.884842519685\n",
        "6 6 1  .....  0.88467847769\n",
        "12 10 1  .....  0.88467847769\n",
        "6 8 1  .....  0.884514435696\n",
        "12 6 3  .....  0.884514435696\n",
        "6 10 3  .....  0.884350393701\n",
        "6 8 2  .....  0.884350393701\n",
        "9 8 2  .....  0.884350393701\n",
        "12 8 1  .....  0.884350393701\n",
        "12 8 3  .....  0.884186351706\n",
        "12 10 2  .....  0.884186351706\n",
        "12 4 2  .....  0.884186351706\n",
        "9 10 2  .....  0.884186351706\n",
        "6 4 1  .....  0.884022309711\n",
        "6 6 2  .....  0.884022309711\n",
        "6 4 3  .....  0.883858267717\n",
        "12 8 2  .....  0.883858267717\n",
        "9 8 1  .....  0.883858267717\n",
        "12 8 3  .....  0.883858267717\n",
        "6 10 2  .....  0.883858267717\n",
        "9 10 1  .....  0.883858267717\n",
        "6 6 3  .....  0.883694225722\n",
        "6 8 1  .....  0.883530183727\n",
        "9 8 1  .....  0.883530183727\n",
        "9 10 1  .....  0.883366141732\n",
        "12 8 3  .....  0.883366141732\n",
        "9 10 1  .....  0.883038057743\n",
        "9 8 2  .....  0.883038057743\n",
        "12 10 3  .....  0.882874015748\n",
        "9 8 3  .....  0.882874015748\n",
        "6 4 1  .....  0.882874015748\n",
        "9 10 1  .....  0.882874015748\n",
        "12 10 3  .....  0.882709973753\n",
        "9 8 1  .....  0.882709973753\n",
        "12 8 2  .....  0.882709973753\n",
        "12 10 1  .....  0.882709973753\n",
        "12 8 3  .....  0.882545931759\n",
        "9 8 1  .....  0.882545931759\n",
        "12 10 3  .....  0.882381889764\n",
        "12 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3  .....  0.88188976378\n",
        "12 6 3  .....  0.88188976378\n",
        "6 6 2  .....  0.88188976378\n",
        "6 10 3  .....  0.88188976378\n",
        "6 8 3  .....  0.881725721785\n",
        "12 8 3  .....  0.88156167979\n",
        "6 4 1  .....  0.88156167979\n",
        "12 8 1  .....  0.88156167979\n",
        "9 4 2  .....  0.881397637795\n",
        "9 6 3  .....  0.881397637795\n",
        "9 10 2  .....  0.881397637795\n",
        "6 6 3  .....  0.881397637795\n",
        "12 8 2  .....  0.881233595801\n",
        "9 4 2  .....  0.881233595801\n",
        "12 8 3  .....  0.881233595801\n",
        "6 6 2  .....  0.881069553806\n",
        "6 8 1  .....  0.881069553806\n",
        "6 4 2  .....  0.880905511811\n",
        "12 10 1  .....  0.880905511811\n",
        "9 8 2  .....  0.880741469816\n",
        "6 8 1  .....  0.880741469816\n",
        "9 8 1  .....  0.880741469816\n",
        "6 6 3  .....  0.880577427822\n",
        "6 8 1  .....  0.880577427822\n",
        "6 8 2  .....  0.880413385827\n",
        "9 4 2  .....  0.880249343832\n",
        "9 8 3  .....  0.880249343832\n",
        "12 4 2  .....  0.880085301837\n",
        "12 4 1  .....  0.880085301837\n",
        "6 10 1  .....  0.879921259843\n",
        "9 4 2  .....  0.879921259843\n",
        "6 6 3  .....  0.879921259843\n",
        "6 4 1  .....  0.879757217848\n",
        "9 8 2  .....  0.879757217848\n",
        "9 10 1  .....  0.879757217848\n",
        "9 10 2  .....  0.879757217848\n",
        "6 6 3  .....  0.879757217848\n",
        "12 6 2  .....  0.879757217848\n",
        "6 10 2  .....  0.879757217848\n",
        "12 10 1  .....  0.879593175853\n",
        "12 4 2  .....  0.879593175853\n",
        "12 10 1  .....  0.879593175853\n",
        "6 8 3  .....  0.879429133858\n",
        "12 10 2  .....  0.879265091864\n",
        "12 10 2  .....  0.879265091864\n",
        "9 8 1  .....  0.879265091864\n",
        "9 8 3  .....  0.879265091864\n",
        "6 10 1  .....  0.879101049869\n",
        "12 10 2  .....  0.879101049869\n",
        "9 4 1  .....  0.878937007874\n",
        "9 8 3  .....  0.878937007874\n",
        "9 6 3  .....  0.878937007874\n",
        "6 10 3  .....  0.878772965879\n",
        "9 8 3  .....  0.878608923885\n",
        "12 4 2  .....  0.878608923885\n",
        "6 4 1  .....  0.87844488189\n",
        "9 8 3  .....  0.878280839895\n",
        "12 4 2  .....  0.878280839895\n",
        "12 10 3  .....  0.8781167979\n",
        "6 8 3  .....  0.8781167979\n",
        "9 4 2  .....  0.8781167979\n",
        "6 10 1  .....  0.877952755906\n",
        "9 10 3  .....  0.877952755906\n",
        "6 10 2  .....  0.877624671916\n",
        "12 6 2  .....  0.877296587927\n",
        "6 8 3  .....  0.876968503937\n",
        "9 8 3  .....  0.876968503937\n",
        "6 6 1  .....  0.876804461942\n",
        "6 6 3  .....  0.876804461942\n",
        "9 4 2  .....  0.876640419948\n",
        "6 6 1  .....  0.876640419948\n",
        "9 10 3  .....  0.876640419948\n",
        "6 4 1  .....  0.876312335958\n",
        "12 8 3  .....  0.876312335958\n",
        "9 8 2  .....  0.876312335958\n",
        "9 8 1  .....  0.876312335958\n",
        "12 8 1  .....  0.876148293963\n",
        "12 4 2  .....  0.876148293963\n",
        "9 10 1  .....  0.876148293963\n",
        "6 4 2  .....  0.875984251969\n",
        "6 4 2  .....  0.875820209974\n",
        "12 10 1  .....  0.875820209974\n",
        "6 8 3  .....  0.875656167979\n",
        "12 4 2  .....  0.875492125984\n",
        "9 10 1  .....  0.875492125984\n",
        "6 8 1  .....  0.875492125984\n",
        "9 10 1  .....  0.87532808399\n",
        "6 6 1  .....  0.87532808399\n",
        "9 4 3  .....  0.87532808399\n",
        "9 6 2  .....  0.874343832021\n",
        "6 10 1  .....  0.874343832021\n",
        "12 10 2  .....  0.874343832021\n",
        "12 6 3  .....  0.874343832021\n",
        "9 8 3  .....  0.874343832021\n",
        "12 10 2  .....  0.874343832021\n",
        "6 6 2  .....  0.874179790026\n",
        "6 10 2  .....  0.874179790026\n",
        "9 10 2  .....  0.874179790026\n",
        "6 10 1  .....  0.874179790026\n",
        "12 10 1  .....  0.874015748031\n",
        "12 6 3  .....  0.873523622047\n",
        "12 10 2  .....  0.873523622047\n",
        "6 10 1  .....  0.873359580052\n",
        "12 10 1  .....  0.873359580052\n",
        "12 8 3  .....  0.873359580052\n",
        "9 10 2  .....  0.872867454068\n",
        "12 10 3  .....  0.872867454068\n",
        "6 8 3  .....  0.872867454068\n",
        "9 4 3  .....  0.872703412073\n",
        "12 6 3  .....  0.872703412073\n",
        "12 10 1  .....  0.872703412073\n",
        "6 10 1  .....  0.872539370079\n",
        "6 10 2  .....  0.872539370079\n",
        "6 8 2  .....  0.872539370079\n",
        "9 6 3  .....  0.872375328084\n",
        "9 10 1  .....  0.872211286089\n",
        "9 8 2  .....  0.872211286089\n",
        "9 10 1  .....  0.872211286089\n",
        "6 10 1  .....  0.8718832021\n",
        "12 10 1  .....  0.87155511811\n",
        "6 8 1  .....  0.87155511811\n",
        "6 8 3  .....  0.871391076115\n",
        "6 10 3  .....  0.871391076115\n",
        "6 10 2  .....  0.871227034121\n",
        "6 8 1  .....  0.871227034121\n",
        "6 10 1  .....  0.871062992126\n",
        "9 10 2  .....  0.871062992126\n",
        "9 4 2  .....  0.870898950131\n",
        "9 10 3  .....  0.870734908136\n",
        "6 10 3  .....  0.870570866142\n",
        "9 8 3  .....  0.870406824147\n",
        "9 10 3  .....  0.870406824147\n",
        "9 6 2  .....  0.870406824147\n",
        "12 8 2  .....  0.870242782152\n",
        "12 8 2  .....  0.870242782152\n",
        "9 4 3  .....  0.870242782152\n",
        "9 10 1  .....  0.870078740157\n",
        "12 10 2  .....  0.870078740157\n",
        "12 10 1  .....  0.869914698163\n",
        "9 4 3  .....  0.869914698163\n",
        "9 10 2  .....  0.869586614173\n",
        "12 10 2  .....  0.869258530184\n",
        "6 10 1  .....  0.869258530184\n",
        "12 10 1  .....  0.868930446194\n",
        "6 10 3  .....  0.868930446194\n",
        "9 10 3  .....  0.868930446194\n",
        "6 4 3  .....  0.868766404199\n",
        "6 10 2  .....  0.868766404199\n",
        "9 10 1  .....  0.868602362205\n",
        "6 8 2  .....  0.868602362205\n",
        "6 10 2  .....  0.868602362205\n",
        "6 6 3  .....  0.868602362205\n",
        "6 4 3  .....  0.86843832021\n",
        "9 10 1  .....  0.868274278215\n",
        "9 8 3  .....  0.868274278215\n",
        "9 4 2  .....  0.868274278215\n",
        "9 6 3  .....  0.86811023622\n",
        "9 10 3  .....  0.86811023622\n",
        "9 10 3  .....  0.86811023622\n",
        "6 6 2  .....  0.867782152231\n",
        "6 8 1  .....  0.867782152231\n",
        "6 10 3  .....  0.867618110236\n",
        "6 10 2  .....  0.867454068241\n",
        "6 6 3  .....  0.867290026247\n",
        "12 10 3  .....  0.867290026247\n",
        "12 10 3  .....  0.866797900262\n",
        "12 6 2  .....  0.866797900262\n",
        "6 4 2  .....  0.866633858268\n",
        "6 10 1  .....  0.866633858268\n",
        "12 6 2  .....  0.866633858268\n",
        "9 10 3  .....  0.866633858268\n",
        "9 10 3  .....  0.866305774278\n",
        "12 10 3  .....  0.865977690289\n",
        "6 10 2  .....  0.865813648294\n",
        "6 4 2  .....  0.865649606299\n",
        "6 8 1  .....  0.865649606299\n",
        "9 8 3  .....  0.865649606299\n",
        "9 8 2  .....  0.865485564304\n",
        "9 4 3  .....  0.86532152231\n",
        "6 10 3  .....  0.864665354331\n",
        "9 4 3  .....  0.864665354331\n",
        "12 8 3  .....  0.864501312336\n",
        "6 8 2  .....  0.864337270341\n",
        "12 10 3  .....  0.864173228346\n",
        "6 10 2  .....  0.864173228346\n",
        "6 8 3  .....  0.864009186352\n",
        "9 10 2  .....  0.863845144357\n",
        "6 10 1  .....  0.863517060367\n",
        "6 6 3  .....  0.863353018373\n",
        "12 10 1  .....  0.863188976378\n",
        "6 8 3  .....  0.863188976378\n",
        "6 6 3  .....  0.863188976378\n",
        "12 6 3  .....  0.863024934383\n",
        "6 10 1  .....  0.862860892388\n",
        "9 10 3  .....  0.862860892388\n",
        "6 10 1  .....  0.862860892388\n",
        "6 8 2  .....  0.862696850394\n",
        "12 6 2  .....  0.862532808399\n",
        "6 10 3  .....  0.862204724409\n",
        "6 8 1  .....  0.862204724409\n",
        "6 4 2  .....  0.86187664042\n",
        "12 6 3  .....  0.861712598425\n",
        "12 8 2  .....  0.861712598425\n",
        "6 4 3  .....  0.86154855643\n",
        "6 4 2  .....  0.86154855643\n",
        "9 4 3  .....  0.861384514436\n",
        "12 8 3  .....  0.861384514436\n",
        "12 4 2  .....  0.861220472441\n",
        "6 10 1  .....  0.861056430446\n",
        "12 10 2  .....  0.861056430446\n",
        "9 10 1  .....  0.861056430446\n",
        "6 6 2  .....  0.860892388451\n",
        "9 6 2  .....  0.860728346457\n",
        "9 10 2  .....  0.860564304462\n",
        "6 10 1  .....  0.860564304462\n",
        "9 10 2  .....  0.860564304462\n",
        "9 8 3  .....  0.860400262467\n",
        "6 6 2  .....  0.860400262467\n",
        "9 10 1  .....  0.860236220472\n",
        "6 8 3  .....  0.860236220472\n",
        "6 10 3  .....  0.859908136483\n",
        "9 4 3  .....  0.859908136483\n",
        "6 10 3  .....  0.859744094488\n",
        "12 4 2  .....  0.859580052493\n",
        "6 6 2  .....  0.859416010499\n",
        "6 8 2  .....  0.859251968504\n",
        "9 10 3  .....  0.858923884514\n",
        "6 10 2  .....  0.858923884514\n",
        "6 8 1  .....  0.858595800525\n",
        "9 8 2  .....  0.858267716535\n",
        "6 4 3  .....  0.858267716535\n",
        "9 10 2  .....  0.858103674541\n",
        "9 10 2  .....  0.857939632546\n",
        "6 10 2  .....  0.857775590551\n",
        "9 6 3  .....  0.857611548556\n",
        "12 8 2  .....  0.857447506562\n",
        "6 10 3  .....  0.857447506562\n",
        "12 10 1  .....  0.857447506562\n",
        "12 6 2  .....  0.857283464567\n",
        "9 10 3  .....  0.857283464567\n",
        "12 10 2  .....  0.857119422572\n",
        "12 6 2  .....  0.857119422572\n",
        "9 10 1  .....  0.857119422572\n",
        "9 10 2  .....  0.856299212598\n",
        "6 10 1  .....  0.856135170604\n",
        "9 6 3  .....  0.855971128609\n",
        "12 8 2  .....  0.855807086614\n",
        "6 4 3  .....  0.855643044619\n",
        "6 10 3  .....  0.855643044619\n",
        "6 8 1  .....  0.855479002625\n",
        "6 10 3  .....  0.85498687664\n",
        "9 4 2  .....  0.85498687664\n",
        "6 6 3  .....  0.854822834646\n",
        "6 4 3  .....  0.854822834646\n",
        "12 10 3  .....  0.854330708661\n",
        "12 10 3  .....  0.854002624672\n",
        "12 10 3  .....  0.852362204724\n",
        "6 10 3  .....  0.85219816273\n",
        "12 10 3  .....  0.85187007874\n",
        "6 10 1  .....  0.85187007874\n",
        "6 10 3  .....  0.851541994751\n",
        "12 6 2  .....  0.851049868766\n",
        "9 10 2  .....  0.850885826772\n",
        "9 6 2  .....  0.850885826772\n",
        "6 10 3  .....  0.850721784777\n",
        "6 10 2  .....  0.850721784777\n",
        "6 6 3  .....  0.850721784777\n",
        "6 8 3  .....  0.850721784777\n",
        "9 6 2  .....  0.850557742782\n",
        "9 10 3  .....  0.850393700787\n",
        "12 10 3  .....  0.850393700787\n",
        "6 10 2  .....  0.850229658793\n",
        "6 8 2  .....  0.850229658793\n",
        "6 6 3  .....  0.850229658793\n",
        "12 4 2  .....  0.849737532808\n",
        "6 4 3  .....  0.849409448819\n",
        "9 10 3  .....  0.849245406824\n",
        "9 10 1  .....  0.848917322835\n",
        "9 8 2  .....  0.84875328084\n",
        "9 4 2  .....  0.84842519685\n",
        "12 10 2  .....  0.84842519685\n",
        "6 8 2  .....  0.848261154856\n",
        "12 10 3  .....  0.848097112861\n",
        "9 8 2  .....  0.847933070866\n",
        "6 10 2  .....  0.847769028871\n",
        "9 8 2  .....  0.847604986877\n",
        "9 10 3  .....  0.846784776903\n",
        "9 8 2  .....  0.846456692913\n",
        "6 4 3  .....  0.846456692913\n",
        "6 4 3  .....  0.846128608924\n",
        "9 6 2  .....  0.846128608924\n",
        "12 8 2  .....  0.846128608924\n",
        "12 8 2  .....  0.84563648294\n",
        "12 10 1  .....  0.844652230971\n",
        "6 10 2  .....  0.844488188976\n",
        "6 4 2  .....  0.844160104987\n",
        "9 10 3  .....  0.843832020997\n",
        "6 10 3  .....  0.843503937008\n",
        "6 6 2  .....  0.843503937008\n",
        "6 4 2  .....  0.841699475066\n",
        "6 8 2  .....  0.841699475066\n",
        "6 10 1  .....  0.841699475066\n",
        "6 10 3  .....  0.840879265092\n",
        "6 6 3  .....  0.840551181102\n",
        "6 4 3  .....  0.840551181102\n",
        "12 4 2  .....  0.838418635171\n",
        "6 4 3  .....  0.838254593176\n",
        "6 10 2  .....  0.837598425197\n",
        "9 4 3  .....  0.837598425197\n",
        "12 4 2  .....  0.836614173228\n",
        "6 10 3  .....  0.835958005249\n",
        "6 8 3  .....  0.835465879265\n",
        "6 4 3  .....  0.835465879265\n",
        "6 10 1  .....  0.83530183727\n",
        "12 6 3  .....  0.834973753281\n",
        "9 4 2  .....  0.834645669291\n",
        "9 6 3  .....  0.834481627297\n",
        "9 4 3  .....  0.834153543307\n",
        "6 10 3  .....  0.834153543307\n",
        "9 6 3  .....  0.833989501312\n",
        "6 10 3  .....  0.833825459318\n",
        "12 4 2  .....  0.833825459318\n",
        "12 8 3  .....  0.833333333333\n",
        "6 10 3  .....  0.833005249344\n",
        "9 4 2  .....  0.833005249344\n",
        "6 8 3  .....  0.832677165354\n",
        "6 10 1  .....  0.832677165354\n",
        "9 10 2  .....  0.831856955381\n",
        "9 4 3  .....  0.831856955381\n",
        "9 4 3  .....  0.831528871391\n",
        "9 10 3  .....  0.831364829396\n",
        "9 10 2  .....  0.830544619423\n",
        "6 4 3  .....  0.830380577428\n",
        "6 10 3  .....  0.829724409449\n",
        "12 8 3  .....  0.829560367454\n",
        "9 4 3  .....  0.829396325459\n",
        "12 10 2  .....  0.829396325459\n",
        "9 8 2  .....  0.829232283465\n",
        "12 8 3  .....  0.82874015748\n",
        "12 10 3  .....  0.828576115486\n",
        "12 8 3  .....  0.828412073491\n",
        "6 10 3  .....  0.827755905512\n",
        "12 6 3  .....  0.827755905512\n",
        "9 6 3  .....  0.827427821522\n",
        "9 10 3  .....  0.826771653543\n",
        "12 10 2  .....  0.826443569554\n",
        "9 4 2  .....  0.82562335958\n",
        "6 4 3  .....  0.825459317585\n",
        "9 4 3  .....  0.824311023622\n",
        "9 8 3  .....  0.823818897638\n",
        "12 8 2  .....  0.822998687664\n",
        "6 4 3  .....  0.82250656168\n",
        "12 10 3  .....  0.82217847769\n",
        "12 10 2  .....  0.82217847769\n",
        "12 6 3  .....  0.821030183727\n",
        "9 8 3  .....  0.820866141732\n",
        "9 10 3  .....  0.820374015748\n",
        "9 10 3  .....  0.820045931759\n",
        "9 10 3  .....  0.820045931759\n",
        "9 10 3  .....  0.819881889764\n",
        "9 10 2  .....  0.81906167979\n",
        "6 10 1  .....  0.818569553806\n",
        "12 10 3  .....  0.815124671916\n",
        "12 10 3  .....  0.814632545932\n",
        "9 8 3  .....  0.814140419948\n",
        "9 6 3  .....  0.813156167979\n",
        "12 10 3  .....  0.81217191601\n",
        "9 4 3  .....  0.810531496063\n",
        "12 6 3  .....  0.80905511811\n",
        "9 8 3  .....  0.807414698163\n",
        "9 10 3  .....  0.807414698163\n",
        "6 10 3  .....  0.806758530184\n",
        "6 10 3  .....  0.805118110236\n",
        "9 4 3  .....  0.79904855643\n",
        "12 10 3  .....  0.79625984252\n",
        "9 10 3  .....  0.794947506562\n",
        "OrderedDict([(9, 383), (6, 383), (12, 351)])"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "OrderedDict([(8, 287), (10, 287), (6, 287), (4, 255)])\n",
        "OrderedDict([(1, 383), (2, 383), (3, 351)])\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Vytvoreni struktury"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ori_keys = noris.keys()\n",
      "ppc_keys = nppcs.keys()\n",
      "cpb_keys = ncpbs.keys()\n",
      "\n",
      "hog_param_struct = dict()\n",
      "\n",
      "for orikey in ori_keys:\n",
      "    hog_param_struct[orikey] = dict()\n",
      "    for ppckey in ppc_keys:\n",
      "        hog_param_struct[orikey][ppckey] = dict()\n",
      "        for cpbkey in cpb_keys:\n",
      "            hog_param_struct[orikey][ppckey][cpbkey] = list()\n",
      "\n",
      "for key, value in ordered.items()[:]:\n",
      "    key = re.sub(\"extractor\\_test\\_results\\/[\\d\\-\\_]+\", \"\", key)\n",
      "    key = re.sub(\"evaluation\", \"\", key)\n",
      "    key = re.findall(\"ori\\=\\d+\\_+ppc\\=\\d+\\_+cpb=\\d+\", key)[0]\n",
      "\n",
      "    ori = find_ori(key)\n",
      "    ppc = find_ppc(key)\n",
      "    cpb = find_cpb(key)\n",
      "    \n",
      "    hog_param_struct[ori][ppc][cpb].append(value)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oris_unwanted = []\n",
      "ppcs_unwanted = [10]\n",
      "cpbs_unwanted = [3]\n",
      "\n",
      "print \"Cpb\"\n",
      "for ori in hog_param_struct.keys():\n",
      "    if ori in oris_unwanted: continue\n",
      "    for ppc in hog_param_struct[ori].keys():\n",
      "        if ppc in ppcs_unwanted: continue\n",
      "        best_cpb = {} \n",
      "        for cpb in hog_param_struct[ori][ppc].keys():\n",
      "            best_cpb[cpb] = np.mean(hog_param_struct[ori][ppc][cpb])\n",
      "        print ori, ppc, OrderedDict(sorted(best_cpb.items(), key=lambda x: -x[1]))\n",
      "# pro vetsinu konfiguraci je nejhorsi cpb=3\n",
      "\n",
      "print \"Ppc\"\n",
      "for ori in ori_keys:\n",
      "    if ori in oris_unwanted: continue\n",
      "    for cpb in cpb_keys:\n",
      "        if cpb in cpbs_unwanted: continue\n",
      "        best_ppc = {} \n",
      "        for ppc in ppc_keys:\n",
      "            best_ppc[ppc] = np.mean(hog_param_struct[ori][ppc][cpb])\n",
      "        print ori, cpb, OrderedDict(sorted(best_ppc.items(), key=lambda x: -x[1]))\n",
      "\n",
      "        #print ori, ppc, OrderedDict(sorted(best_cpb.items(), key=lambda x: -x[1]))\n",
      "# pro vetsinu konfiguraci je nejhorsi ppc=10\n",
      "\n",
      "print \"Ori\"\n",
      "for ppc in ppc_keys:\n",
      "    if ppc in ppcs_unwanted: continue\n",
      "    for cpb in cpb_keys:\n",
      "        if cpb in cpbs_unwanted: continue\n",
      "        best_ori = {} \n",
      "        for ori in ori_keys:\n",
      "            best_ori[ori] = np.mean(hog_param_struct[ori][ppc][cpb])\n",
      "        print ppc, cpb, OrderedDict(sorted(best_ori.items(), key=lambda x: -x[1]))\n",
      "# pro vetsinu konfiguraci je nejhorsi ori="
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cpb\n",
        "9 8 OrderedDict([(1, 0.90323060203412076), (2, 0.89009698982939633), (3, 0.88256643700787407)])\n",
        "9 4 OrderedDict([(1, 0.92034223261154846), (2, 0.896484375), (3, 0.88283813156167978)])\n",
        "9 6 OrderedDict([(1, 0.91572855150918642), (2, 0.90176447670603666), (3, 0.89056861056430447)])\n",
        "12 8 OrderedDict([(1, 0.90469672736220474), (2, 0.89098384186351698), (3, 0.88724163385826771)])\n",
        "12 4 OrderedDict([(1, 0.9186608021653544), (2, 0.8956026492782152), (3, nan)])\n",
        "12 6 OrderedDict([(1, 0.91573880413385833), (2, 0.90094426673228345), (3, 0.89047121062992129)])\n",
        "6 8 OrderedDict([(2, 0.89155286253280841), (1, 0.88876927493438318), (3, 0.88533977198162728)])\n",
        "6 4 OrderedDict([(1, 0.91088418635170609), (2, 0.89960629921259838), (3, 0.88419147801837272)])\n",
        "6 6 OrderedDict([(1, 0.90266158136482932), (2, 0.90173371883202103), (3, 0.89302924048556431)])\n",
        "Ppc\n",
        "9 1 OrderedDict([(4, 0.92034223261154846), (6, 0.91572855150918642), (8, 0.90323060203412076), (10, 0.8858011400918635)])\n",
        "9 2 OrderedDict([(6, 0.90176447670603666), (4, 0.896484375), (8, 0.89009698982939633), (10, 0.87832697670603677)])\n",
        "12 1 OrderedDict([(4, 0.9186608021653544), (6, 0.91573880413385833), (8, 0.90469672736220474), (10, 0.88747744422572183)])\n",
        "12 2 OrderedDict([(6, 0.90094426673228345), (4, 0.8956026492782152), (8, 0.89098384186351698), (10, 0.88190514271653542)])\n",
        "6 1 OrderedDict([(4, 0.91088418635170609), (6, 0.90266158136482932), (8, 0.88876927493438318), (10, 0.87275980150918642)])\n",
        "6 2 OrderedDict([(6, 0.90173371883202103), (4, 0.89960629921259838), (8, 0.89155286253280841), (10, 0.87780921916010501)])\n",
        "Ori\n",
        "8 1 OrderedDict([(12, 0.90469672736220474), (9, 0.90323060203412076), (6, 0.88876927493438318)])\n",
        "8 2 OrderedDict([(6, 0.89155286253280841), (12, 0.89098384186351698), (9, 0.89009698982939633)])\n",
        "4 1 OrderedDict([(9, 0.92034223261154846), (12, 0.9186608021653544), (6, 0.91088418635170609)])\n",
        "4 2 OrderedDict([(6, 0.89960629921259838), (9, 0.896484375), (12, 0.8956026492782152)])\n",
        "6 1 OrderedDict([(12, 0.91573880413385833), (9, 0.91572855150918642), (6, 0.90266158136482932)])\n",
        "6 2 OrderedDict([(9, 0.90176447670603666), (6, 0.90173371883202103), (12, 0.90094426673228345)])\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Serazeni prumeru pro danou HoG konfiguraci"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg = {}\n",
      "\n",
      "for ori in hog_param_struct.keys():\n",
      "    for ppc in hog_param_struct[ori].keys():\n",
      "        for cpb in hog_param_struct[ori][ppc].keys():\n",
      "            avg[(ori, ppc, cpb)] = np.mean(hog_param_struct[ori][ppc][cpb])\n",
      "            \n",
      "avg = OrderedDict(sorted(avg.items(), key=lambda x: -x[1]))\n",
      "\n",
      "for key, value in avg.items():\n",
      "    print key, \" ..... \", value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(9, 4, 1)  .....  0.920342232612\n",
        "(12, 4, 1)  .....  0.918660802165\n",
        "(12, 6, 1)  .....  0.915738804134\n",
        "(9, 6, 1)  .....  0.915728551509\n",
        "(6, 4, 1)  .....  0.910884186352\n",
        "(12, 8, 1)  .....  0.904696727362\n",
        "(9, 8, 1)  .....  0.903230602034\n",
        "(6, 6, 1)  .....  0.902661581365\n",
        "(9, 6, 2)  .....  0.901764476706\n",
        "(6, 6, 2)  .....  0.901733718832\n",
        "(12, 6, 2)  .....  0.900944266732\n",
        "(6, 4, 2)  .....  0.899606299213\n",
        "(9, 4, 2)  .....  0.896484375\n",
        "(12, 4, 2)  .....  0.895602649278\n",
        "(6, 6, 3)  .....  0.893029240486\n",
        "(6, 8, 2)  .....  0.891552862533\n",
        "(12, 8, 2)  .....  0.890983841864\n",
        "(9, 6, 3)  .....  0.890568610564\n",
        "(12, 6, 3)  .....  0.89047121063\n",
        "(9, 8, 2)  .....  0.890096989829\n",
        "(6, 8, 1)  .....  0.888769274934\n",
        "(12, 10, 1)  .....  0.887477444226\n",
        "(12, 8, 3)  .....  0.887241633858\n",
        "(9, 10, 1)  .....  0.885801140092\n",
        "(6, 8, 3)  .....  0.885339771982\n",
        "(6, 4, 3)  .....  0.884191478018\n",
        "(9, 4, 3)  .....  0.882838131562\n",
        "(9, 8, 3)  .....  0.882566437008\n",
        "(12, 10, 2)  .....  0.881905142717\n",
        "(9, 10, 2)  .....  0.878326976706\n",
        "(6, 10, 2)  .....  0.87780921916\n",
        "(6, 10, 1)  .....  0.872759801509\n",
        "(12, 10, 3)  .....  0.867833415354\n",
        "(12, 4, 3)  .....  nan\n",
        "(9, 10, 3)  .....  0.860518167651\n",
        "(6, 10, 3)  .....  0.858293348097\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Poronavani konfiguraci dat"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hog_param_struct_proc = dict()\n",
      "\n",
      "for orikey in ori_keys:\n",
      "    hog_param_struct_proc[orikey] = dict()\n",
      "    for ppckey in ppc_keys:\n",
      "        hog_param_struct_proc[orikey][ppckey] = dict()\n",
      "        for cpbkey in cpb_keys:\n",
      "            hog_param_struct_proc[orikey][ppckey][cpbkey] = dict()\n",
      "\n",
      "for key1, value in ordered.items()[:]:\n",
      "    \n",
      "    key = re.sub(\"extractor\\_test\\_results\\/[\\d\\-\\_]+\", \"\", key1)\n",
      "    key = re.sub(\"evaluation\", \"\", key)\n",
      "    key = re.findall(\"ori\\=\\d+\\_+ppc\\=\\d+\\_+cpb=\\d+\", key)[0]\n",
      "    \n",
      "    ori = find_ori(key)\n",
      "    ppc = find_ppc(key)\n",
      "    cpb = find_cpb(key)\n",
      "\n",
      "    hog_param_struct_proc[ori][ppc][cpb][key1] = value   \n",
      "    \n",
      "mode = \"win\"\n",
      "#mode = \"proc\"\n",
      "#mode = \"col\"\n",
      "for orikey in ori_keys:\n",
      "    if orikey in oris_unwanted: continue\n",
      "    for ppckey in ppc_keys:\n",
      "        if ppckey in ppcs_unwanted: continue\n",
      "        for cpbkey in cpb_keys:\n",
      "            if cpbkey in cpbs_unwanted: continue\n",
      "            \n",
      "            medians = list()\n",
      "            bilaterals = list()\n",
      "            \n",
      "            coloring = list()\n",
      "            nocoloring = list()\n",
      "            \n",
      "            win48 = list()\n",
      "            win54 = list()\n",
      "            \n",
      "            for key, value in hog_param_struct_proc[orikey][ppckey][cpbkey].items():\n",
      "                if \"median\" in key:\n",
      "                    medians.append(value)\n",
      "                if \"bilat\" in key:\n",
      "                    bilaterals.append(value)\n",
      "                if \"oloring2\" in key:\n",
      "                    coloring.append(value)\n",
      "                if \"NOcolor\" in key:\n",
      "                    nocoloring.append(value)\n",
      "                if \"48\" in key:\n",
      "                    win48.append(value)\n",
      "                else:\n",
      "                    win54.append(value)\n",
      "                key = re.sub(\"extractor\\_test\\_results\\/[\\d\\-\\_]+\", \"\", key1)\n",
      "                key = re.sub(\"evaluation\", \"\", key)\n",
      "            print orikey, ppckey, cpbkey, \":\",\n",
      "            if mode == \"proc\":\n",
      "                print len(medians), len(bilaterals), \"median\", np.mean(medians), \" x \", np.mean(bilaterals), \"bilateral\",\n",
      "                print \"==>\", \"median\" if np.mean(medians) > np.mean(bilaterals) else \"bilateral\"\n",
      "            if mode == \"win\":\n",
      "                print len(win48), len(win54), \"win48\", np.mean(win48), \" x \", np.mean(win54), \"win54\",\n",
      "                print \"==>\", \"win48\" if np.mean(win48) > np.mean(win54) else \"        54\"   \n",
      "            if mode == \"col\":\n",
      "                print len(coloring), len(nocoloring), \"coloring\", np.mean(coloring), \" x \", np.mean(nocoloring), \"no_coloring\",\n",
      "                print \"==>\", \"coloring\" if np.mean(coloring) > np.mean(nocoloring) else \"         no_coloring\" \n",
      "\n",
      "# lepsi je win 48 v drtive vetsine\n",
      "# lepsi je coloring -> ale ne vzdy uplne -> v tech vyznamnych ale ano\n",
      "# lepsi je median, vzdy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9 8 1 : 16 16 win48 0.908567093176  x  0.897894110892 win54 ==> win48\n",
        "9 8 2 : 16 16 win48 0.895187417979  x  0.88500656168 win54 ==> win48\n",
        "9 4 1 : 16 16 win48 0.924581692913  x  0.91610277231 win54 ==> win48\n",
        "9 4 2 : 17 15 win48 0.898766790181  x  0.893897637795 win54 ==> win48\n",
        "9 6 1 : 16 16 win48 0.91500574147  x  0.916451361549 win54 ==>         54\n",
        "9 6 2 : 16 16 win48 0.903235728346  x  0.900293225066 win54 ==> win48\n",
        "12 8 1 : 16 16 win48 0.910607365486  x  0.898786089239 win54 ==> win48\n",
        "12 8 2 : 16 16 win48 0.895187417979  x  0.886780265748 win54 ==> win48\n",
        "12 4 1 : 16 16 win48 0.922551673228  x  0.914769931102 win54 ==> win48\n",
        "12 4 2 : 16 16 win48 0.896920111549  x  0.894285187008 win54 ==> win48\n",
        "12 6 1 : 16 16 win48 0.915979740814  x  0.915497867454 win54 ==> win48\n",
        "12 6 2 : 17 15 win48 0.901864289023  x  0.899901574803 win54 ==> win48\n",
        "6 8 1 : 16 16 win48 0.891137631234  x  0.886400918635 win54 ==> win48\n",
        "6 8 2 : 16 16 win48 0.89608964895  x  0.887016076115 win54 ==> win48\n",
        "6 4 1 : 16 16 win48 0.912924458661  x  0.908843914042 win54 ==> win48\n",
        "6 4 2 : 16 16 win48 0.902138697507  x  0.897073900919 win54 ==> win48\n",
        "6 6 1 : 16 16 win48 0.899421751969  x  0.905901410761 win54 ==>         54\n",
        "6 6 2 : 16 16 win48 0.903389517717  x  0.900077919948 win54 ==> win48\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Confussion matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, recall_score, precision_score\n",
      "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict\n",
      "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
      "from sklearn.svm import SVC\n",
      "import data_reader as dr\n",
      "import time\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = dr.load_obj(\"extractor_test_results/All/data.pklz\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, scoring=scorings, n_jobs=-1)\n",
      "# vypsani vysledku\n",
      "print \"[RESULT] Vysledne skore: \"\n",
      "for key, value in scores.items():\n",
      "    if \"test\" in key or \"time\" in key:\n",
      "        print \"    - \", key, \":\", np.mean(value)\n",
      "        \n",
      "# vzdy vyhodi to same \n",
      "# [RESULT] Vysledne skore: \n",
      "#    -  test_f1 : 0.88553008794\n",
      "#    -  test_recall : 0.809521734647\n",
      "#    -  score_time : 8.59933328629\n",
      "#    -  fit_time : 26.6599999269\n",
      "#    -  test_accuracy : 0.894831364062\n",
      "#    -  test_precision : 0.982314078606"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TN, FP, FN, TP = confusion_matrix(y, scores).ravel()\n",
      "print \"TN = \", tn\n",
      "print \"FP = \", fp\n",
      "print \"FN = \", fn\n",
      "print \"TP = \", tp\n",
      "\n",
      "precision = precision_score(y, scores)\n",
      "recall = recall_score(y, scores)\n",
      "f1 = f1_score(y, scores)\n",
      "accuracy = accuracy_score(y, scores)\n",
      "\n",
      "print \"presicion: \", precision\n",
      "print \"   recall: \", recall\n",
      "print \"       f1: \", f1\n",
      "print \" accuracy: \", accuracy\n",
      "\n",
      "scores_to_save = {\"precision\": precision,\n",
      "                  \"recall\": recall,\n",
      "                  \"f1\": f1,\n",
      "                  \"accuracy\": accuracy,\n",
      "                  \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN}\n",
      "\n",
      "print scores_to_save\n",
      "\n",
      "# take vzdy vyhodi to same\n",
      "# TN =  1920\n",
      "# FP =  32\n",
      "# FN =  387\n",
      "# TP =  1645\n",
      "# presicion:  0.9809183065\n",
      "#    recall:  0.809547244094\n",
      "#        f1:  0.887031544891\n",
      "#  accuracy:  0.894829317269"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
      "scores = cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=kf, scoring=scorings, n_jobs=-1)\n",
      "scoresp = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=kf, n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Provnani cross_validate a cross_val_predict \"\"\"\n",
      "\n",
      "indexes = np.arange(0, len(y), len(y)//3)\n",
      "\n",
      "indexes = np.hstack((indexes, len(y)+1))\n",
      "\n",
      "for i in range(3):\n",
      "\n",
      "    print \" ---- Split \", i, \" ------- \"\n",
      "    print indexes[i], \" az \", indexes[i+1]\n",
      "    \n",
      "    tn, fp, fn, tp = confusion_matrix(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]).ravel()\n",
      "    print tn, tp, fn, fp\n",
      "    \n",
      "    print \"presicion: \", precision_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_precision\"][i]\n",
      "    \n",
      "    print \"   recall: \", recall_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_recall\"][i]\n",
      "    \n",
      "    print \"       f1: \", f1_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_f1\"][i]\n",
      "    \n",
      "    print \" accuracy: \", accuracy_score(y[indexes[i]:indexes[i+1]], scoresp[indexes[i]:indexes[i+1]]),\n",
      "    print \" x \", scores[\"test_accuracy\"][i]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test rychlosti"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "#scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=7, n_jobs=-1)\n",
      "print time.time()-t\n",
      "# 104.861999989 s n_jobs=-1 .... cv=7\n",
      "# 224.183000088 bez n_jobs (=1) ... cv=7\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test rychlosti\n",
      "for i in range(2, 7):\n",
      "    \n",
      "    t = time.time()\n",
      "    scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=i)#, n_jobs=-1)\n",
      "    #cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=i)#, n_jobs=-1)\n",
      "    print \"Pro \", i, \" : \", time.time()-t\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cross_validate -> viz papir\n",
      "\n",
      "# cross_val_predict:\n",
      "# --- n_jobs = -1 \n",
      "#   Pro  2  :  16.6150000095\n",
      "#   Pro  3  :  32.2750000954\n",
      "#   Pro  4  :  50.2630000114\n",
      "#   Pro  5  :  72.2149999142\n",
      "#   Pro  6  :  82.4709999561\n",
      "# --- n_jobs nezadano\n",
      "#   Pro  2  :  26.1459999084\n",
      "#   Pro  3  :  58.1630001068\n",
      "#   Pro  4  :  92.4739999771\n",
      "#   Pro  5  :  129.036000013\n",
      "#   Pro  6  :  167.592999935"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=6, n_jobs=-1)\n",
      "#cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=6, n_jobs=-1)\n",
      "print \"Pro 6: \", time.time()-t\n",
      "\n",
      "t = time.time()\n",
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "scores = cross_val_predict(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "#cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "#cross_validate(SVC(kernel=\"linear\", C = 0.15, probability=True, random_state=42), X, y, cv=3, n_jobs=-1)\n",
      "print \"Pro 2x3: \", time.time()-t\n",
      "\n",
      "#     Cross_validate\n",
      "# Pro 6:    95.9859998226\n",
      "# Pro 2x3:  73.6770000458\n",
      "\n",
      "#     Cross_val_predict\n",
      "# Pro 6:    81.0869998932\n",
      "# Pro 2x3:  58.8340001106"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test rozdeleni dat"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "clf = SVC(kernel=\"linear\", C = 0.1, probability=True, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myX = np.array([[6, 1], [1, 9], [8, 1], [1, 5], [6, 2], [6, 1], [3, 1], [2, 9], [2, 6]], dtype=float)\n",
      "myy = np.array([1, -1, 1, -1, 1, 1, 1, -1, -1])\n",
      "\n",
      "indx = np.argsort(myy)[::-1]\n",
      "print indx\n",
      "\n",
      "myX = myX[indx]\n",
      "myy = myy[indx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = train_test_split(myX, myy, shuffle=True, random_state=None, test_size=0.33)\n",
      "print cross_val_predict(clf, myX, myy, cv=3)\n",
      "print myy\n",
      "print cv[2], cv[3]\n",
      "cv = train_test_split(myX, range(myX.shape[0]), shuffle=True, random_state=None, test_size=0.33)\n",
      "print cv[2], cv[3]\n",
      "cv = train_test_split(myX, range(myX.shape[0]), shuffle=True, random_state=None, test_size=0.33)\n",
      "print cv[2], cv[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myX = np.vstack((myX, myX))\n",
      "myy = np.hstack((myy, myy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
      "kf.get_n_splits()\n",
      "\n",
      "\n",
      "print(kf)  \n",
      "for train_index, test_index in kf.split(myX):\n",
      "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "    print(\"TRAIN:\", myy[train_index], \"TEST:\", myy[test_index])\n",
      "    X_train, X_test = myX[train_index], myX[test_index]\n",
      "    y_train, y_test = myy[train_index], myy[test_index]\n",
      "    \n",
      "print cross_val_predict(clf, myX, myy, cv=kf)\n",
      "print myy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skf = StratifiedKFold(n_splits=8)\n",
      "skf.get_n_splits(myX, myy)\n",
      "\n",
      "for train_index, test_index in skf.split(myX, myy):\n",
      "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "    X_train, X_test = myX[train_index], myX[test_index]\n",
      "    y_train, y_test = myy[train_index], myy[test_index]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Rozdeleni dat pro nas dataset \"\"\"\n",
      "\n",
      "print \"Celkem dat: \"\n",
      "print \"   \" + str( len([s for s in y if s > 0]) ) + \" pozitivnich\"\n",
      "print \"   \" + str( len([s for s in y if s < 0]) ) + \" negativnich\"\n",
      "\n",
      "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
      "\n",
      "print(kf)\n",
      "\n",
      "for train_index, test_index in kf.split(X):\n",
      "    print \"  TRAIN:\" + str( len([s for s in y[train_index] if s > 0]) ) + \" P + \" + str( len([s for s in y[train_index] if s < 0]) ) + \" N \",\n",
      "    print \"  TEST:\" + str( len([s for s in y[test_index] if s > 0]) ) + \" P + \" + str( len([s for s in y[test_index] if s < 0]) ) + \" N \"\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list([1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Test prekryti bounding boxu a artefaktu"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import data_reader as dr\n",
      "import file_manager as fm\n",
      "from skimage.morphology import label\n",
      "import matplotlib.pyplot as plt\n",
      "import cv2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = dr.DATAset()\n",
      "dataset.create_dataset_CT()\n",
      "config = dataset.config\n",
      "\n",
      "results = dr.load_json(config[\"result_path\"]+\"results_nms.json\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TP, TN, FP, FN = 0, 0, 0, 0\n",
      "\n",
      "for imgname, boxes in results.items():\n",
      "    \n",
      "    img = dr.load_image(imgname)\n",
      "    mask = fm.get_mask(imgname, config)\n",
      "    imlabel = label(mask)\n",
      "    imlabel[mask==0] = 0\n",
      "    imlabel[mask==2] = 0\n",
      "    blank = np.zeros(img.shape)\n",
      "   \n",
      "    for y, h, x, w in boxes:\n",
      "\n",
      "        frame = img[y:h, x:w]\n",
      "        mask_frame = mask[y:h, x:w]\n",
      "        \n",
      "        na = np.sum((mask_frame==1).astype(int))\n",
      "        nb = frame.shape[0] * frame.shape[1]\n",
      "        \n",
      "        bb_artefact_coverage = float(na) / nb\n",
      "        \n",
      "        print bb_artefact_coverage\n",
      "        \n",
      "        if bb_artefact_coverage < 0.5:\n",
      "            FP += 1\n",
      "            print \"false_positive\"\n",
      "        \n",
      "        print \"-------------------------------\"\n",
      "    \n",
      "    print \"_______________________________\"\n",
      "    artefact_ids = np.unique(imlabel)[1:]\n",
      "    \n",
      "    for i in artefact_ids:\n",
      "        \n",
      "        maxbox = [0, 0]\n",
      "        max_cov = 0\n",
      "        max_id = 0\n",
      "        \n",
      "        for j, (y, h, x, w) in enumerate(boxes):\n",
      "            blank[y:h, x:w] = 1\n",
      "            \n",
      "            na = np.sum((imlabel==i).astype(int))\n",
      "            nab = np.sum((imlabel==i) & (blank==1))\n",
      "\n",
      "            artefact_bb_coverage = float(nab)/na\n",
      "            \n",
      "            if artefact_bb_coverage > max_cov:\n",
      "                max_cov = artefact_bb_coverage\n",
      "                max_id = j\n",
      "                \n",
      "            blank[y:h, x:w] = 0\n",
      "            \n",
      "        print max_cov\n",
      "        \n",
      "        y, h, x, w = max_box = boxes[max_id]\n",
      "        mask_frame = mask[y:h, x:w]\n",
      "        na = np.sum((mask_frame==1).astype(int))\n",
      "        nb = mask_frame.shape[0] * mask_frame.shape[1]\n",
      "        bb_artefact_coverage = float(na) / nb\n",
      "        \n",
      "        print na, nb, max_id\n",
      "        print bb_artefact_coverage\n",
      "        \n",
      "        if bb_artefact_coverage < 0.5:\n",
      "            FN += 1\n",
      "            print \"false_positive\"\n",
      "        else:\n",
      "            TP += 1\n",
      "        \n",
      "        print \"-------------------------------\"\n",
      "\n",
      "        \n",
      "    \n",
      "    print artefact_ids\n",
      "    \n",
      "    print \"TP:\", TP\n",
      "    print \"TN:\", TN\n",
      "    print \"FP:\", FP\n",
      "    print \"FN:\", FN\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plt.imshow(mask)\n",
      "#plt.show()\n",
      "\n",
      "imlabel = label(mask)\n",
      "print np.unique(imlabel)\n",
      "plt.imshow(imlabel)\n",
      "plt.show()\n",
      "\n",
      "imlabel[mask==0] = 0\n",
      "imlabel[mask==2] = 0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TP, TN, FP, FN = 0, 0, 0, 0\n",
      "\n",
      "\n",
      "for imgname, boxes in results.items():\n",
      "    print imgname\n",
      "    TP0, TN0, FP0, FN0 = 0, 0, 0, 0\n",
      "    \n",
      "    img = dr.load_image(imgname)\n",
      "    mask = fm.get_mask(imgname, config)\n",
      "    imlabel = label(mask)\n",
      "    imlabel[(mask==0) | (mask==2)] = 0\n",
      "    #imlabel[mask==2] = 0\n",
      "    blank = np.zeros(img.shape)\n",
      "    artefact_ids = np.unique(imlabel)[1:]\n",
      "    covered_box_ids = list()\n",
      "    \n",
      "    for i in artefact_ids:\n",
      "        covered_by_bb = False\n",
      "        \n",
      "        for j, (y, h, x, w) in enumerate(boxes):\n",
      "            blank[y:h, x:w] = 1\n",
      "            \n",
      "            na = np.sum((imlabel==i).astype(int))\n",
      "            nab = np.sum((imlabel==i) & (blank==1))\n",
      "\n",
      "            artefact_bb_coverage = float(nab)/na\n",
      "            \n",
      "            if artefact_bb_coverage >= 0.5:\n",
      "                covered_by_bb=True\n",
      "                covered_box_ids.append(j)\n",
      "                mask_frame = mask[y:h, x:w]\n",
      "                bb_artefact_coverage = clas.fe.artefact_coverage(mask_frame)\n",
      "                bb_artefact_center_coverage, _ = artefact_center_ellipse_coverage(mask_frame)\n",
      "                if bb_artefact_coverage >= 0.3 and bb_artefact_center_coverage > 0.8:\n",
      "                    print bb_artefact_coverage, bb_artefact_center_coverage\n",
      "                    TP += 1\n",
      "                    TP0 += 1\n",
      "                else:\n",
      "                    print bb_artefact_coverage, bb_artefact_center_coverage\n",
      "                    FP += 1\n",
      "                    FP0 += 1\n",
      "            blank[y:h, x:w] = 0\n",
      "            \n",
      "        if not covered_by_bb:\n",
      "            FN += 1\n",
      "            FN0 += 1\n",
      "    \n",
      "    for j in range(len(boxes)):\n",
      "        if not j in covered_box_ids:\n",
      "            y, h, x, w = boxes[j]\n",
      "            mask_frame = mask[y:h, x:w]\n",
      "            na = np.sum((mask_frame==1).astype(int))\n",
      "            nb = mask_frame.shape[0] * mask_frame.shape[1]\n",
      "            bb_artefact_coverage = float(na) / nb\n",
      "            if bb_artefact_coverage >= 0.5:\n",
      "                TP += 1\n",
      "                TP0 += 1\n",
      "            else:\n",
      "                FP += 1\n",
      "                FP0 += 1\n",
      "    print TP0, TN0, FP0, FN0\n",
      "    #break\n",
      "  \n",
      "    #FP += len(boxes) - len(covered_box_ids)\n",
      "\n",
      "print \"TP:\", TP\n",
      "print \"TN:\", TN\n",
      "print \"FP:\", FP\n",
      "print \"FN:\", FN\n",
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def artefact_center_ellipse_coverage(mask_frame, smaller_scale=0.6):\n",
      "    \"\"\" Vytvori presne uprostred framu oblast ve tvaru elipsy,\n",
      "    a vrati zastoupeni jater uvnitr \"\"\"\n",
      "    \n",
      "    # urceni rozmeru masky\n",
      "    c = np.array(mask_frame.shape) // 2\n",
      "    # vytvoremi masky elipsy\n",
      "    ellipse_mask = clas.fe.ellipse(c, smaller_scale=smaller_scale)\n",
      "    # zprava velikosti podle masky frmu\n",
      "    ellipse_mask = cv2.resize(ellipse_mask.astype(\"uint8\"), mask_frame.shape[::-1], interpolation = cv2.INTER_CUBIC)\n",
      "    \n",
      "    # vytazeni pozadovane oblasti z masky framu\n",
      "    mask_ellipse_frame = mask_frame[ellipse_mask==True]\n",
      "    \n",
      "    # vypocet zastoupeni jater v oblasti\n",
      "    total = np.sum(ellipse_mask >= 1).astype(int)\n",
      "    artefact = np.sum(mask_ellipse_frame == 1).astype(int)\n",
      "    coverage = float(artefact) / total\n",
      "    \n",
      "    return coverage, ellipse_mask"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = dict()\n",
      "print len(a.keys())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm.evaluate_nms_results_overlap()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}